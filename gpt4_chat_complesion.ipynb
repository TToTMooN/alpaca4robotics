{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "OPENAI_KEY = str(json.load(open(\"openai_key.json\"))['key'])\n",
    "openai.api_key = OPENAI_KEY\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_robot_instruction import encode_task_generation_prompt, generate_task_data, encode_instruct_prompt, generate_instruction_following_chat_data, post_process_chat_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [[{'role': 'user', 'content': 'You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on the table, here we use 2 blocks as an example. The blocks are called {block A} and {block B}. \\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weights.\\n<move> The blocks are randomly determined to be movable or not; at least one block is movable.\\n<three> There are three blocks in the environment.\\n<four> There are four blocks in the environment.\\n\\n[Your Task]\\nCome up with 50 different tasks for the robot to perform. Each is designed under the assumption tags.\\n\\n[Output format]\\nThe response should follow the template below:\\n### Task {i}: {task tag}{task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn\\'t need to include all the objects in the environment.\\n3. The robot\\'s basic skills are reach, grasp, and place. The task should not be out of its capability.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height of the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. You can include tasks with different levels of difficulty. Eazy tasks have short action sequences. Harder tasks have longer horizons which requires reasoning in planning.\\n8. Some tasks are not solvable with the initial observation. There are uncertainties in the task that require the robot to explore the environment to gather information. For tasks you think satisfy this requirement, please add a * at the end of the task description.\\n9. At least 30% of the tasks should be non-solvable with the initial observation. \\n10. Tags can be combined together.\\n\\n[Example]\\nExamples of {task tag}{task description}: \\n<weight> pick up the heavier block and place it on top of the lighter block*\\n<move> find the movable block and place it on top of the other block.\\n<weight> move the heavier block to the corner of the table\\n<three><weight> sort all the blocks by their weight\\n<three> stack the three blocks\\n\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "prompts: 100%|██████████| 1/1 [01:34<00:00, 94.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' Task 1: <weight> Pick up the heavier block\\n', ' Task 2: <move> Find the movable block and place it on top of the other block*\\n', ' Task 3: <weight> Move the heavier block to the corner of the table*\\n', ' Task 4: <three><weight> Sort all the blocks by their weight*\\n', ' Task 5: <three> Stack the three blocks\\n', ' Task 6: <weight> Pick up the lighter block\\n', ' Task 7: <three> Pick up the middle block in height\\n', ' Task 8: <four> Move the heaviest block to the left corner of the table, and the lightest block to the right corner*\\n', ' Task 9: <four> Move the two blocks in the middle to the back edge of the table*\\n', ' Task 10: <move> Pick up the only movable block and hold it for 5 seconds*\\n', ' Task 11: <weight><move> Pick up the movable and lighter block\\n', ' Task 12: <four> Stack two of the blocks together\\n', ' Task 13: <four> Arrange the blocks in a square formation*\\n', ' Task 14: <three> Place the blocks in a straight line with equal distance between them*\\n', ' Task 15: <three><weight> Stack the blocks in order of their weight, with the heaviest at the bottom*\\n', ' Task 16: <move> Find a block that is both movable and lighter, if possible, and place it on top of the heavier block*\\n', ' Task 17: <weight> Hold the heavier block in the gripper for 10 seconds\\n', ' Task 18: <three><weight> Pick up the block with the medium weight\\n', ' Task 19: <three> Rearrange the blocks to form a triangle*\\n', ' Task 20: <four> Swap the positions of the lightest and the heaviest blocks*\\n', ' Task 21: <move> Find the block with the lightest color and move it to the front edge of the table*\\n', ' Task 22: <three> Move the block closest to the end effector to the farthest point from the robot*\\n', ' Task 23: <three> Place all the blocks so they are in contact with each other*\\n', ' Task 24: <weight> Place the lighter block on the heavier block, but only if the difference in height is less than 5cm*\\n', ' Task 25: <move> Arrange the movable blocks side by side*\\n', \" Task 26: <four> Move all the blocks to the left side of the table, making sure they don't touch each other*\\n\", ' Task 27: <three> Stack the three blocks in random order*\\n', \" Task 28: <three> Place the middle block near the robot's starting position*\\n\", ' Task 29: <four> Pick up a block of your choice and hold it for 7 seconds\\n', ' Task 30: <four> Move the heaviest block to the middle of the table*\\n', ' Task 31: <move> Move one of the movable blocks to the right side of the table*\\n', ' Task 32: <three> Place one block on top of the other two, making a bridge*\\n', ' Task 33: <three> Place the smallest block next to the largest block*\\n', ' Task 34: <weight> Determine which block has the densest material*\\n', ' Task 35: <weight><move> Find the heaviest movable block and push the other blocks with it*\\n', ' Task 36: <four> Stack a pair of two blocks, and place the other two blocks on their sides*\\n', ' Task 37: <four> Organize the blocks alphabetically by color*\\n', \" Task 38: <four> Find a block that is both the heaviest and the farthest from the robot, if possible, and place it close to the robot's starting position*\\n\", ' Task 39: <move> Determine which block has the most uneven surface and find a way to balance it on its edge*\\n', \" Task 40: <three> Pick up a block and place it on the robot's left side, then another block on the right side*\\n\", ' Task 41: <weight> Pick up the lightest block and drop it on the heaviest block*\\n', ' Task 42: <move> Find a movable block that is not the heaviest and place it next to the heaviest block*\\n', ' Task 43: <three><weight> Move the heaviest block to the left side, the lightest block to the right side, and the middle-weighted block to the back of the table*\\n', ' Task 44: <three> Move one block to each corner of the table*\\n', ' Task 45: <four> Stack one of the movable blocks on top of another, making it as close to the other blocks as possible*\\n', \" Task 46: <four> Swap two of the blocks' positions*, and leave the other two untouched\\n\", ' Task 47: <three> Create a tower of blocks with the middle block as the base\\n', ' Task 48: <three><weight> Re-stack the blocks, starting with the lightest on the bottom*\\n', ' Task 49: <move> Find a movable block that is not the lightest and place it next to the lightest block*\\n', ' Task 50: <four> Rearrange the blocks in ascending order of size, from left to right*']\n",
      "Request 1 took 94.20s\n",
      "Generated 50 tasks, kept 50 instructions\n",
      "### [[{'role': 'user', 'content': 'You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on the table, here we use 2 blocks as an example. The blocks are called {block A} and {block B}. \\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weights.\\n<move> The blocks are randomly determined to be movable or not; at least one block is movable.\\n<three> There are three blocks in the environment.\\n<four> There are four blocks in the environment.\\n\\n[Your Task]\\nCome up with 50 different tasks for the robot to perform. Each is designed under the assumption tags.\\n\\n[Output format]\\nThe response should follow the template below:\\n### Task {i}: {task tag}{task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn\\'t need to include all the objects in the environment.\\n3. The robot\\'s basic skills are reach, grasp, and place. The task should not be out of its capability.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height of the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. You can include tasks with different levels of difficulty. Eazy tasks have short action sequences. Harder tasks have longer horizons which requires reasoning in planning.\\n8. Some tasks are not solvable with the initial observation. There are uncertainties in the task that require the robot to explore the environment to gather information. For tasks you think satisfy this requirement, please add a * at the end of the task description.\\n9. At least 30% of the tasks should be non-solvable with the initial observation. \\n10. Tags can be combined together.\\n\\n[Example]\\nExamples of {task tag}{task description}: \\n<weight> pick up the heavier block and place it on top of the lighter block*\\n<move> find the movable block and place it on top of the other block.\\n<weight> move the heavier block to the corner of the table\\n<three><weight> sort all the blocks by their weight\\n<three> stack the three blocks\\n\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "prompts: 100%|██████████| 1/1 [01:46<00:00, 106.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' Task 1: <weight> Pick up the heaviest block*\\n', ' Task 2: <move> Find the movable block and place it on top of the other block*\\n', ' Task 3: <weight> Move the heavier block to the corner of the table*\\n', ' Task 4: <three><weight> Sort all the blocks by their weight*\\n', ' Task 5: <three> Stack the three blocks*\\n\\n', ' Task 6: <four> Stack the four blocks in a 2x2 square*\\n', ' Task 7: <move><three> Move the immovable block between the two movable blocks.\\n', ' Task 8: <weight><three> Place the lightest block on top of the heaviest block*\\n', ' Task 9: <four> Create a pyramid with the four blocks*\\n', ' Task 10: <move> Move a movable block to the edge of the table*\\n\\n', ' Task 11: <weight><three> Move the lightest block on top of the medium-weight block*\\n', ' Task 12: <move><four> Move all the movable blocks to one corner of the table*\\n', ' Task 13: <weight> Move the heaviest block on top of the lightest block*\\n', ' Task 14: <three> Create a straight line with the three blocks*\\n', ' Task 15: <four> Arrange the four blocks to form a square*\\n\\n', ' Task 16: <weight><move> Place the heaviest movable block on top of the lightest movable block*\\n', ' Task 17: <four> Stack the four blocks to form a tower*\\n', ' Task 18: <move><four> Find the movable blocks and place them side by side*\\n', ' Task 19: <weight> Place the heaviest block on the left and the lightest block on the right*\\n', ' Task 20: <three> Place the middle-weight block on top of the other two blocks*\\n\\n', ' Task 21: <move><weight> Place the heaviest movable block next to the immovable block*\\n', ' Task 22: <move><three> Move the two movable blocks on top of the immovable block*\\n', ' Task 23: <weight><four> Stack the blocks according to their weight, from heaviest to lightest*\\n', ' Task 24: <weight><three> Move the heaviest block to the farthest corner of the table. Place the two lighter blocks next to it.\\n', ' Task 25: <four> Move the end blocks to the center*\\n\\n', ' Task 26: <move><four> Place the movable blocks to form the base of a pyramid*\\n', ' Task 27: <weight> Move the lightest block to the center of the table*\\n', ' Task 28: <three> Move the lightest block between the two heavier blocks*\\n', ' Task 29: <four> Arrange the four blocks to form a rectangle*\\n', ' Task 30: <move><weight> Move the lightest movable block to the edge of the table*\\n\\n', ' Task 31: <move> Place the movable block on top of the immovable block*\\n', ' Task 32: <weight><move> Move the heaviest movable block to the highest point on the table*\\n', ' Task 33: <three> Move the heaviest block in between the two lighter blocks*\\n', ' Task 34: <four> Create a 2x2 stacked cubic formation.\\n', ' Task 35: <weight><three> Move the lightest block on the left and the heaviest block on the right*\\n\\n', ' Task 36: <weight> Place the lightest block on top of the heaviest block while leaving the lightest block touching the table*\\n', ' Task 37: <move> Move the movable block to the opposite corner of the table*\\n', ' Task 38: <four> Create a stair formation with the four blocks*\\n', ' Task 39: <weight><three> Move the lightest block on the left, the heaviest block on the right, and the middle-weight block on top*\\n', ' Task 40: <four><move> Arrange the movable blocks in a triangle formation*\\n\\n', ' Task 41: <move><three> Place the immovable block on the right and the two movable blocks on the left*\\n', ' Task 42: <four> Maximize the height of the four blocks*\\n', ' Task 43: <move><weight> Move the lightest movable block on top of the heaviest movable block*\\n', ' Task 44: <three> Stack the three blocks in descending order of weight*\\n', ' Task 45: <four> Create an inverted pyramid formation with the four blocks*\\n\\n', ' Task 46: <move> Move the movable block to the midpoint of the table*\\n', ' Task 47: <weight> Move the two blocks far apart without changing the order of lightest to heaviest*\\n', ' Task 48: <three><weight> Move the heaviest and lightest blocks next to each other with the middle block stacked on top*\\n', ' Task 49: <four> Place the four blocks to form the corners of a large square*\\n', ' Task 50: <move><weight> Move the heaviest movable block next to the lightest immovable block*']\n",
      "Request 2 took 106.44s\n",
      "Generated 50 tasks, kept 50 instructions\n",
      "### [[{'role': 'user', 'content': 'You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on the table, here we use 2 blocks as an example. The blocks are called {block A} and {block B}. \\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weights.\\n<move> The blocks are randomly determined to be movable or not; at least one block is movable.\\n<three> There are three blocks in the environment.\\n<four> There are four blocks in the environment.\\n\\n[Your Task]\\nCome up with 50 different tasks for the robot to perform. Each is designed under the assumption tags.\\n\\n[Output format]\\nThe response should follow the template below:\\n### Task {i}: {task tag}{task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn\\'t need to include all the objects in the environment.\\n3. The robot\\'s basic skills are reach, grasp, and place. The task should not be out of its capability.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height of the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. You can include tasks with different levels of difficulty. Eazy tasks have short action sequences. Harder tasks have longer horizons which requires reasoning in planning.\\n8. Some tasks are not solvable with the initial observation. There are uncertainties in the task that require the robot to explore the environment to gather information. For tasks you think satisfy this requirement, please add a * at the end of the task description.\\n9. At least 30% of the tasks should be non-solvable with the initial observation. \\n10. Tags can be combined together.\\n\\n[Example]\\nExamples of {task tag}{task description}: \\n<weight> pick up the heavier block and place it on top of the lighter block*\\n<move> find the movable block and place it on top of the other block.\\n<weight> move the heavier block to the corner of the table\\n<three><weight> sort all the blocks by their weight\\n<three> stack the three blocks\\n\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "prompts: 100%|██████████| 1/1 [01:40<00:00, 100.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' Task 1: <weight> Pick up the heavier block and place it on top of the lighter block*\\n', ' Task 2: <move> Find the movable block and place it on top of the other block.\\n', ' Task 3: <weight> Move the heavier block to the corner of the table.\\n', ' Task 4: <three><weight> Sort all the blocks by their weight.\\n', ' Task 5: <three> Stack the three blocks.\\n', ' Task 6: <weight> Pick up the lighter block and place it on the other side of the table.\\n', ' Task 7: <move> Stack the movable block on top of the unmovable block.\\n', ' Task 8: <three> Create a bridge between the three blocks horizontally.\\n', ' Task 9: <four> Make a pyramid using all four blocks.\\n', ' Task 10: <weight> Elevate the lighter block as high as possible.\\n', ' Task 11: <move> Transfer the movable block to a designated location on the table.\\n', ' Task 12: <weight> Set the two blocks next to each other in increasing weight order from left to right.\\n', ' Task 13: <three> Arrange the three blocks in a row parallel to the edge of the table.\\n', ' Task 14: <three><weight> Stack the three blocks in descending order of weight.\\n', ' Task 15: <four> Arrange the four blocks in a square.\\n', ' Task 16: <weight> Move the lighter block to one edge of the table and the heavier block to the opposite edge.*\\n', ' Task 17: <move> Make a small gap between the movable block and the other block.\\n', ' Task 18: <weight> Stack the lighter block on the heavier block without the lighter block touching the table.\\n', ' Task 19: <three> Create an incline using two blocks, while keeping the third block on top.\\n', ' Task 20: <four> Balance the four blocks on top of each other.*\\n', ' Task 21: <weight> Move the heavier block to the center of the table.\\n', ' Task 22: <move> Transfer the movable block from one corner of the table to the opposite corner.\\n', ' Task 23: <three> Create an L-shape using the blocks.\\n', ' Task 24: <four><weight> Organize the four blocks in ascending weight order in a straight line.\\n', ' Task 25: <weight> Place the two blocks side by side with a specific distance apart.\\n', ' Task 26: <three><move> Stack the movable block in between the other two blocks.\\n', ' Task 27: <four> Arrange the four blocks in a straight line parallel to the edge of the table.\\n', ' Task 28: <three> Stack the three blocks in a spiral.\\n', ' Task 29: <move> Place the movable block vertically on its edge.*\\n', ' Task 30: <three><weight> Stack the three blocks horizontally in a line increasing in weight from left to right.\\n', ' Task 31: <weight> Raise the heavier block and hold it in the air.*\\n', ' Task 32: <move> Place the movable block leaning on the other block without changing the position of the non-movable block.\\n', ' Task 33: <four> Arrange the four blocks in a T-shape.\\n', ' Task 34: <three><move> Rotate the movable block 180 degrees, then place it on top of the other two blocks.\\n', ' Task 35: <weight> Hold the lighter block using two fingers.*\\n', ' Task 36: <three><four> Swap the position of block A with block B.*\\n', ' Task 37: <four> Make an S-shape using all four blocks.\\n', ' Task 38: <weight> Lower the heavier block to the lowest point without touching the table.\\n', ' Task 39: <three><move> Move the movable block close to another block to form a V-shape.\\n', ' Task 40: <four> Stack the four blocks inside the gripper.*\\n', ' Task 41: <weight> Rotate the heavier block by 90 degrees and place it on its side.*\\n', ' Task 42: <move> Hold the movable block using only one finger.*\\n', ' Task 43: <three> Make an arch using one block to support the other two blocks.\\n', ' Task 44: <four> Arrange the four blocks in a cross (+) shape.\\n', ' Task 45: <weight> Place the lighter block on top of the heavier block as high as possible.*\\n', ' Task 46: <move> Place the movable block inside the gripper without fully closing it.*\\n', ' Task 47: <three> Touch all three blocks simultaneously.\\n', ' Task 48: <four><weight> Stack the blocks, two on the left half of the table and two on the right half of the table, with descending order of weight.*\\n', ' Task 49: <weight> Rotate the lighter block by 45 degrees and place it on top of the heavier block.*\\n', ' Task 50: <move> Place the movable block horizontally at the highest point possible.']\n",
      "Request 3 took 100.25s\n",
      "Generated 50 tasks, kept 50 instructions\n",
      "### [[{'role': 'user', 'content': 'You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on the table, here we use 2 blocks as an example. The blocks are called {block A} and {block B}. \\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weights.\\n<move> The blocks are randomly determined to be movable or not; at least one block is movable.\\n<three> There are three blocks in the environment.\\n<four> There are four blocks in the environment.\\n\\n[Your Task]\\nCome up with 50 different tasks for the robot to perform. Each is designed under the assumption tags.\\n\\n[Output format]\\nThe response should follow the template below:\\n### Task {i}: {task tag}{task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn\\'t need to include all the objects in the environment.\\n3. The robot\\'s basic skills are reach, grasp, and place. The task should not be out of its capability.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height of the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. You can include tasks with different levels of difficulty. Eazy tasks have short action sequences. Harder tasks have longer horizons which requires reasoning in planning.\\n8. Some tasks are not solvable with the initial observation. There are uncertainties in the task that require the robot to explore the environment to gather information. For tasks you think satisfy this requirement, please add a * at the end of the task description.\\n9. At least 30% of the tasks should be non-solvable with the initial observation. \\n10. Tags can be combined together.\\n\\n[Example]\\nExamples of {task tag}{task description}: \\n<weight> pick up the heavier block and place it on top of the lighter block*\\n<move> find the movable block and place it on top of the other block.\\n<weight> move the heavier block to the corner of the table\\n<three><weight> sort all the blocks by their weight\\n<three> stack the three blocks\\n\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "prompts: 100%|██████████| 1/1 [01:45<00:00, 105.40s/it]\n",
      "100%|██████████| 200/200 [06:46<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' Task 1: <weight> pick up the heavier block and place it on top of the lighter block*\\n', ' Task 2: <move> find the movable block and place it on top of the other block*\\n', ' Task 3: <weight> move the heavier block to the corner of the table\\n', ' Task 4: <three><weight> sort all the blocks by their weight*\\n', ' Task 5: <three> stack the three blocks\\n\\n', ' Task 6: <move> transfer the movable block to the opposite corner of the table\\n', ' Task 7: <weight> place the lighter block on top of the heavier block, ensuring they are aligned*\\n', ' Task 8: <three> create a triangle formation with the blocks on the table\\n', ' Task 9: <three><move> find and stack the two movable blocks*\\n', ' Task 10: <weight> swap the positions of the two blocks by weight*\\n\\n', ' Task 11: <three> arrange the blocks in a straight line, sorted by their positions on the table\\n', ' Task 12: <four> create a 2x2 square formation with the four blocks\\n', ' Task 13: <weight> balance the lighter block on top of the heavier block, touching only one edge of the heavier block*\\n', ' Task 14: <move> move the non-movable block without touching it by manipulating the movable block*\\n', ' Task 15: <three> stack the three blocks in descending order of size*\\n\\n', ' Task 16: <weight> place the lighter block as far away from the edge of the table as possible\\n', ' Task 17: <weight> hold the heavier block above the lighter block for 10 seconds*\\n', ' Task 18: <move> spin the movable block on one of its corners*\\n', ' Task 19: <three> align the three blocks along the diagonal of the table\\n', ' Task 20: <four> stack the four blocks into two columns of two blocks each, sorted from left to right*\\n\\n', ' Task 21: <weight> drop the heavier block onto the lighter block so they stick together*\\n', ' Task 22: <move> stack the movable block on top of the non-movable block without touching the non-movable block*\\n', ' Task 23: <three> transfer the middle-weight block from one edge of the table to the other\\n', ' Task 24: <four> arrange the blocks in a diamond shape\\n', ' Task 25: <weight> use the heavier block to nudge the lighter block closer to the edge of the table*\\n\\n', ' Task 26: <move> pick up the movable block, spin it around, and place it back in its original position\\n', ' Task 27: <weight> toss the lighter block in the air and catch it in the parallel gripper*\\n', ' Task 28: <three> create a pyramid using the three blocks\\n', ' Task 29: <four> arrange the blocks in a Z shape\\n', ' Task 30: <weight> find the heaviest block and place it in the center of the table*\\n\\n', \" Task 31: <move> move the movable block so it's touching the non-movable block without causing them to topple\\n\", ' Task 32: <three> move the lightest block and place it on top of the heaviest block*\\n', ' Task 33: <four> create a stair-like formation with the four blocks from left to right\\n', ' Task 34: <weight> identify the second heaviest block*\\n', ' Task 35: <move> lift the non-movable block using the movable block as a lever*\\n\\n', \" Task 36: <three> move the middle block so it's equidistant from the other two blocks\\n\", ' Task 37: <four> create a 4x1 row of blocks, sorted by their position on the table\\n', ' Task 38: <weight> switch the positions of the two lightest blocks*\\n', ' Task 39: <move> move the movable block in a circle around the non-movable block without touching it\\n', ' Task 40: <four> swap the positions of the two adjacent blocks in any direction*\\n\\n', ' Task 41: <weight> separate the lighter block from the heavier block by at least a certain distance\\n', ' Task 42: <move> balance the movable block on its edge*\\n', ' Task 43: <three> balance the heaviest block on top of the two lighter blocks*\\n', ' Task 44: <four> stack the four blocks in a vertical line\\n', ' Task 45: <weight> gently lift the heavier block without applying excessive force to the force sensor*\\n\\n', ' Task 46: <move> move the movable block in an S-shape pattern without changing its orientation\\n', ' Task 47: <three> balance the lightest block on its corner*\\n', ' Task 48: <four> create a capital letter \"H\" with the four blocks\\n', ' Task 49: <weight> move the lighter block without moving the heavier block, even when they are leaning on each other*\\n', ' Task 50: <move> create a square plane using the movable and non-movable blocks']\n",
      "Request 4 took 105.40s\n",
      "Generated 50 tasks, kept 50 instructions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_task_data(\n",
    "    output_dir=\"./gpt4_generation/task_generation_v2/\",\n",
    "    num_tasks_to_generate=200,\n",
    "    prompt_file_name=\"./prompts_for_gpt/robot_task_prompt_v2.txt\",\n",
    "    model_name=\"gpt-4-0314\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def f(x):\n",
    "  return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  with mp.Pool() as pool:\n",
    "    result = pool.map(f, [1, 2, 3])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split task data\n",
    "Split it into tasks used by instruction generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import string\n",
    "import json\n",
    "def split_json_file(json_file, \n",
    "                    output_path, n=2):\n",
    "  \"\"\"Splits a JSON file into N JSONL files, where each file contains n elements.\n",
    "\n",
    "  Args:\n",
    "    json_file: The path to the JSON file to split.\n",
    "    n: The number of JSONL files to create.\n",
    "\n",
    "  Returns:\n",
    "    The list of paths to the created JSONL files.\n",
    "  \"\"\"\n",
    "\n",
    "  with open(json_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "  os.makedirs(output_path, exist_ok=True)\n",
    "  jsonl_files = []\n",
    "  for i in range(0, len(data), n):\n",
    "    jsonl_file = f\"{output_path}split_{i // n}.jsonl\"\n",
    "    with open(jsonl_file, \"w\") as outfile:\n",
    "      for record in data[i : i + n]:\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "    jsonl_files.append(jsonl_file)\n",
    "  return jsonl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_files = split_json_file(json_file=\"./gpt4_generation/task_generation_v2/task_regen.json\",\n",
    "                              output_path=\"./gpt4_generation/task_generation_v2/\",\n",
    "                              n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate COT instruct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './subtask_data/sub_skill_example_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgenerate_robot_instruction\u001b[39;00m \u001b[39mimport\u001b[39;00m generate_instruction_following_chat_data\n\u001b[0;32m----> 4\u001b[0m ret \u001b[39m=\u001b[39m generate_instruction_following_chat_data(output_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./gpt4_generation/cot_full_v5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m                                         instruction_prompt_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./prompts_for_gpt/robot_cot_prompts_v5.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m                                         seed_example_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./prompts_for_gpt/seeded_example_cot_v4.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m                                         seed_tasks_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./gpt4_generation/task_generation_v2/split_0.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m                                         num_instructions_to_generate\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m                                         num_of_tasks_each_request\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m                                         use_sub_skill_data\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     11\u001b[0m                                         output_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcot_instrut_regen.json\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m                                         )\n",
      "File \u001b[0;32m~/codebase/alpaca4robotics/generate_robot_instruction.py:330\u001b[0m, in \u001b[0;36mgenerate_instruction_following_chat_data\u001b[0;34m(output_dir, instruction_prompt_file, seed_tasks_path, seed_example_path, function_file_path, subskill_data_path, use_sub_skill_data, num_instructions_to_generate, model_name, num_of_tasks_each_request, request_batch_size, temperature, top_p, output_file, num_cpus)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m use_sub_skill_data:\n\u001b[1;32m    329\u001b[0m     subskill_data \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 330\u001b[0m     examples \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mjload(subskill_data_path)\n\u001b[1;32m    331\u001b[0m     \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m examples:\n\u001b[1;32m    332\u001b[0m         data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mskill_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m}\n",
      "File \u001b[0;32m~/codebase/alpaca4robotics/utils.py:285\u001b[0m, in \u001b[0;36mjload\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjload\u001b[39m(f, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    284\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a .json file into a dictionary.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     f \u001b[39m=\u001b[39m _make_r_io_base(f, mode)\n\u001b[1;32m    286\u001b[0m     jdict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    287\u001b[0m     f\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/codebase/alpaca4robotics/utils.py:259\u001b[0m, in \u001b[0;36m_make_r_io_base\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_r_io_base\u001b[39m(f, mode: \u001b[39mstr\u001b[39m):\n\u001b[1;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(f, io\u001b[39m.\u001b[39mIOBase):\n\u001b[0;32m--> 259\u001b[0m         f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(f, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    260\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './subtask_data/sub_skill_example_data.json'"
     ]
    }
   ],
   "source": [
    "from generate_robot_instruction import generate_instruction_following_chat_data\n",
    "\n",
    "\n",
    "ret = generate_instruction_following_chat_data(output_dir=\"./gpt4_generation/cot_full_v5\",\n",
    "                                        instruction_prompt_file=\"./prompts_for_gpt/robot_cot_prompts_v5.txt\",\n",
    "                                        seed_example_path=\"./prompts_for_gpt/seeded_example_cot_v4.jsonl\",\n",
    "                                        seed_tasks_path=\"./gpt4_generation/task_generation_v2/split_0.jsonl\",\n",
    "                                        num_instructions_to_generate=500,\n",
    "                                        num_of_tasks_each_request=3,\n",
    "                                        use_sub_skill_data=True,\n",
    "                                        output_file=\"cot_instrut_regen.json\"\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Pick up the heavier block and place it on top of the lighter block*\\'}\\n2. {\\'task\\': \\'<move> Find the movable block and place it on top of the other block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:32<00:00, 152.83s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/500 [02:32<21:00:49, 152.83s/it]\n",
      "Request 1 took 152.83s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Move the heavier block to the corner of the table*\\'}\\n2. {\\'task\\': \\'<three><weight> Sort all the blocks by their weight*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:36<00:00, 96.17s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/500 [04:08<4:51:39, 35.64s/it]\n",
      "Request 2 took 96.17s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Stack the three blocks*\\'}\\n2. {\\'task\\': \\'<weight><move> Move both the movable and the heavier block to the opposite ends of the table*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:34<00:00, 154.79s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/500 [06:43<5:00:27, 37.17s/it]\n",
      "Request 3 took 154.79s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Arrange the four blocks in a square formation*\\'}\\n2. {\\'task\\': \\'<three> Form a pyramid with the three blocks*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:26<00:00, 146.14s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 21/500 [09:09<4:03:48, 30.54s/it]\n",
      "Request 4 took 146.14s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Stack the four blocks in a balanced column*\\'}\\n2. {\\'task\\': \"<weight> Balance the heavier block on top of the lighter block\\'s edge*\"}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:44<00:00, 104.25s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 25/500 [10:54<3:17:28, 24.94s/it]\n",
      "Request 5 took 104.25s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Stack the movable blocks on one side of the table and the non-movable blocks on the other side*\\'}\\n2. {\\'task\\': \\'<four> Arrange the blocks in a line from the heaviest to lightest*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:30<00:00, 90.01s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 29/500 [12:24<3:10:17, 24.24s/it]\n",
      "Request 6 took 90.02s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Move the largest block to the center of the table and the other blocks around it, forming a triangle*\\'}\\n2. {\\'task\\': \\'<three><weight> Place the heaviest block on top of the two lighter blocks, forming a bridge*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:48<00:00, 168.64s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 35/500 [15:12<3:48:22, 29.47s/it]\n",
      "Request 7 took 168.65s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Swap the positions of the heavier block and the lighter block without moving any other block*\\'}\\n2. {\\'task\\': \\'<three><move> Stack the blocks on top of each other such that only one is touching the table*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:19<00:00, 139.01s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 41/500 [17:31<3:26:53, 27.05s/it]\n",
      "Request 8 took 139.01s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><move> Push the non-movable blocks to the opposite end of the table without lifting them*\\'}\\n2. {\\'task\\': \\'<four> Form a rectangular wall with the four blocks*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:30<00:00, 150.65s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 47/500 [20:02<3:19:00, 26.36s/it]\n",
      "Request 9 took 150.66s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Pick up and shake the heavier block after finding it*\\'}\\n2. {\\'task\\': \\'<three> Stack the blocks such that no two edges are aligned*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:56<00:00, 116.28s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|█         | 53/500 [21:58<2:58:53, 24.01s/it]\n",
      "Request 10 took 116.29s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><move> Swap the positions of the movable block with the heavier block*\\'}\\n2. {\\'task\\': \\'<three> Stack the blocks in a zigzag pattern*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:04<00:00, 124.61s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 57/500 [24:03<2:49:31, 22.96s/it]\n",
      "Request 11 took 124.61s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Stand the movable block on one of its corners*\\'}\\n2. {\\'task\\': \\'<four> Create a staircase with alternating movable and non-movable blocks*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:36<00:00, 96.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 61/500 [25:39<2:49:49, 23.21s/it]\n",
      "Request 12 took 96.08s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Use the gripper and force sensor to sense the block weights without fully picking them up*\\'}\\n2. {\\'task\\': \\'<four> Create a hollow square with the four blocks as corners*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:05<00:00, 125.77s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 66/500 [27:45<3:02:55, 25.29s/it]\n",
      "Request 13 took 125.78s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three><move> Place the movable block between the other two blocks*\\'}\\n2. {\\'task\\': \\'<three><weight> Stack the lightest block on top of the middle-weight block, and then stack the heaviest block on top*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:14<00:00, 134.86s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 70/500 [30:00<3:04:59, 25.81s/it]\n",
      "Request 14 took 134.87s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Stack the blocks in a spiral pattern*\\'}\\n2. {\\'task\\': \\'<weight> Move the heaviest block to the opposite corner of the table*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:19<00:00, 79.90s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 74/500 [31:20<2:52:24, 24.28s/it]\n",
      "Request 15 took 79.90s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Create a 2x2 square with the blocks*\\'}\\n2. {\\'task\\': \\'<move> Stack the movable blocks on one side of the table and push the non-movable blocks to the other side*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:32<00:00, 92.44s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 78/500 [32:52<2:48:33, 23.97s/it]\n",
      "Request 16 took 92.45s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Stack the blocks vertically in a straight line*\\'}\\n2. {\\'task\\': \\'<four> Arrange the blocks in a diamond shape on the table*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:08<00:00, 128.16s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 82/500 [35:00<3:02:43, 26.23s/it]\n",
      "Request 17 took 128.17s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Propel the lighter block on its edge by pushing it*\\'}\\n2. {\\'task\\': \\'<three><move> Stack the blocks such that the set of them resembles a pendulum*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:23<00:00, 143.58s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 88/500 [37:24<3:19:04, 28.99s/it]\n",
      "Request 18 took 143.59s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Create a cube configuration by connecting the blocks with their opposite corners touching*\\'}\\n2. {\\'task\\': \\'<weight> Use the force sensor to push the lighter block across the table without lifting it*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:06<00:00, 126.24s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 91/500 [39:30<2:57:02, 25.97s/it]\n",
      "Request 19 took 126.24s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Stack the blocks as high as possible*\\'}\\n2. {\\'task\\': \\'<move> Restack the blocks such that the previously blocked bottom block is the top block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:55<00:00, 115.56s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 95/500 [41:26<3:13:22, 28.65s/it]\n",
      "Request 20 took 115.56s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Create a cross formation with the four blocks*\\'}\\n2. {\\'task\\': \\'<three><weight> Place the lightest block on the heaviest block, and the medium-weight block on top of the lightest block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:28<00:00, 88.92s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 99/500 [42:55<2:59:04, 26.79s/it]\n",
      "Request 21 took 88.92s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Form a V-shape with the blocks*\\'}\\n2. {\\'task\\': \\'<weight> Lift the heaviest block with the minimum force possible*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 25 Aug 2023 03:36:00 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7fc0c1f05e843b69-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [07:31<00:00, 451.47s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21%|██        | 105/500 [50:26<5:41:58, 51.95s/it]\n",
      "Request 22 took 451.47s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Stack the movable blocks and non-movable blocks in alternating layers*\\'}\\n2. {\\'task\\': \\'<weight> Test the weight of both blocks and if both are equal, stack them*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:41<00:00, 221.90s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 109/500 [54:08<5:00:58, 46.18s/it]\n",
      "Request 23 took 221.90s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Stack the movable and non-movable blocks on top of each other, making sure each block is stacked on a different block type*\\'}\\n2. {\\'task\\': \\'<four> Arrange the blocks in a triangle shape with one block in the center*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:39<00:00, 159.88s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 115/500 [56:48<4:45:39, 44.52s/it]\n",
      "Request 24 took 159.88s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three><weight> Place the heaviest block underneath the lighter blocks, supporting them*\\'}\\n2. {\\'task\\': \\'<four> Create a symmetrical square with the blocks by arranging them diagonally*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:16<00:00, 196.38s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 121/500 [1:00:04<4:14:01, 40.22s/it]\n",
      "Request 25 took 196.39s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Pick up the heavier block*\\'}\\n2. {\\'task\\': \\'<move> Find the movable block and place it on top of the immovable block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:31<00:00, 151.64s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 129/500 [1:02:36<3:37:00, 35.10s/it]\n",
      "Request 26 took 151.65s\n",
      "Generated 8 instructions, kept 8 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><move> Swap the positions of the movable block and the heavier block\\'}\\n2. {\\'task\\': \\'<three> Stack the three blocks in any order\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:15<00:00, 135.76s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 135/500 [1:04:52<2:49:56, 27.94s/it]\n",
      "Request 27 took 135.76s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Create a row with the four blocks\\'}\\n2. {\\'task\\': \\'<weight> Move the lighter block to the edge of the table\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:00<00:00, 180.52s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 142/500 [1:07:52<2:50:30, 28.58s/it]\n",
      "Request 28 took 180.52s\n",
      "Generated 7 instructions, kept 7 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><three> Sort the three blocks by their weight\\'}\\n2. {\\'task\\': \\'<three><move> Move the immovable block by pushing it with the movable block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [04:57<00:00, 297.66s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 150/500 [1:12:50<3:13:39, 33.20s/it]\n",
      "Request 29 took 297.66s\n",
      "Generated 8 instructions, kept 8 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Pick up two blocks and stack them one on top of the other\\'}\\n2. {\\'task\\': \\'<weight> Move the lighter block on top of the heavier block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:10<00:00, 130.23s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|███       | 156/500 [1:15:00<2:36:16, 27.26s/it]\n",
      "Request 30 took 130.23s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Push the immovable block to the corner of the table*\\'}\\n2. {\\'task\\': \\'<weight> Place the heavier block in between the end effector and the lighter block\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:25<00:00, 145.35s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 161/500 [1:17:25<2:29:19, 26.43s/it]\n",
      "Request 31 took 145.36s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Create an increasing height order of the three blocks\\'}\\n2. {\\'task\\': \\'<weight><three> Move the lighter block between the other two blocks\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:04<00:00, 124.73s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 166/500 [1:19:30<2:25:06, 26.07s/it]\n",
      "Request 32 took 124.73s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Create a square formation with the four blocks\\'}\\n2. {\\'task\\': \\'<three> Move the leftmost block to the rightmost position\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:28<00:00, 88.31s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 170/500 [1:20:59<2:11:21, 23.88s/it]\n",
      "Request 33 took 88.32s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><move> Move the immovable block by using the heavier block*\\'}\\n2. {\\'task\\': \\'<weight><four> Stack the two lighter blocks on top of each other*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:31<00:00, 151.68s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 174/500 [1:23:30<2:27:13, 27.10s/it]\n",
      "Request 34 took 151.68s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><four><move> Sort the movable blocks by their weight\\'}\\n2. {\\'task\\': \\'<three><move> Rotate the movable block to a specific orientation\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 25 Aug 2023 04:16:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7fc0fd6688854cf3-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [07:31<00:00, 451.50s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 177/500 [1:31:02<4:19:38, 48.23s/it]\n",
      "Request 35 took 451.51s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Move the movable block to the edge of the table\\'}\\n2. {\\'task\\': \\'<four> Create a two by two formation with the blocks\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:20<00:00, 140.10s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 183/500 [1:33:22<4:13:08, 47.91s/it]\n",
      "Request 36 took 140.10s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Stack the blocks in decreasing height order\\'}\\n2. {\\'task\\': \\'<weight> Maximize the height of the two blocks*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:30<00:00, 150.19s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 187/500 [1:35:52<3:25:20, 39.36s/it]\n",
      "Request 37 took 150.19s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><three> Place the heaviest block under the other two blocks\\'}\\n2. {\\'task\\': \\'<four><move> Place the movable blocks on top of each other\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:11<00:00, 71.68s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 191/500 [1:37:04<2:53:44, 33.73s/it]\n",
      "Request 38 took 71.68s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><three> Stack the heaviest block in the middle of the other two blocks\\'}\\n2. {\\'task\\': \\'<move> Move the movable block from the highest position to the lowest position\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:17<00:00, 137.43s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 195/500 [1:39:21<2:52:21, 33.91s/it]\n",
      "Request 39 took 137.43s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Stack the blocks in the following order: A, B, C, D\\'}\\n2. {\\'task\\': \\'<weight><move> Touch the lighter block without changing its position\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:28<00:00, 148.96s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [1:41:50<2:53:37, 34.84s/it]\n",
      "Request 40 took 148.97s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Create a bridge formation with the three blocks\\'}\\n2. {\\'task\\': \\'<weight><four> Move the heaviest block to the edge of the table\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:44<00:00, 104.79s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41%|████      | 206/500 [1:43:35<2:18:46, 28.32s/it]\n",
      "Request 41 took 104.80s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Arrange the blocks in a diagonal line\\'}\\n2. {\\'task\\': \\'<weight><move> Bring the movable block closer to the heavier block\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:15<00:00, 135.87s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 212/500 [1:45:51<2:14:14, 27.97s/it]\n",
      "Request 42 took 135.87s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Stack the blocks such that the middle block is on the bottom\\'}\\n2. {\\'task\\': \\'<move> Place the movable block vertically\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:36<00:00, 96.49s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 217/500 [1:47:27<1:52:30, 23.85s/it]\n",
      "Request 43 took 96.49s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Arrange the blocks in an X formation\\'}\\n2. {\\'task\\': \\'<weight><four> Bring the lighter block closer to the heaviest block\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ").\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [04:20<00:00, 260.50s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 223/500 [1:51:48<2:28:11, 32.10s/it]\n",
      "Request 44 took 260.51s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Align the three blocks along the edge of the table\\'}\\n2. {\\'task\\': \\'<weight><move> Stack the movable block on top of the heavier block\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:10<00:00, 70.31s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 227/500 [1:52:58<1:55:07, 25.30s/it]\n",
      "Request 45 took 70.31s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Place the blocks in alternating height order\\'}\\n2. {\\'task\\': \\'<weight><four> Sort all four blocks by their weight\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:31<00:00, 91.02s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 230/500 [1:54:29<1:51:06, 24.69s/it]\n",
      "Request 46 took 91.02s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Move the middle block to the left of the leftmost block\\'}\\n2. {\\'task\\': \\'<weight> Move both blocks to opposite corners of the table\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:51<00:00, 111.37s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 234/500 [1:56:21<2:00:46, 27.24s/it]\n",
      "Request 47 took 111.37s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four><move> Move the movable blocks diagonally from each other\\'}\\n2. {\\'task\\': \\'<three> Rotate all three blocks to have the same orientation\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 234/500 [1:56:23<2:00:46, 27.24s/it]\n",
      "Request 48 took 2.27s\n",
      "Generated 0 instructions, kept 0 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Flip the movable block 180 degrees\\'}\\n2. {\\'task\\': \\'<four> Form a pyramid structure with the four blocks\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:45<00:00, 105.69s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 238/500 [1:58:09<1:58:39, 27.17s/it]\n",
      "Request 49 took 105.69s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Move the heavier block to be parallel to the lighter block\\'}\\n2. {\\'task\\': \\'<three><move> Place the movable block in between the other two blocks, forming a line\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:57<00:00, 237.22s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 246/500 [2:02:06<2:34:00, 36.38s/it]\n",
      "Request 50 took 237.22s\n",
      "Generated 8 instructions, kept 8 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:13<00:00, 133.74s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 249/500 [2:04:20<1:55:09, 27.53s/it]\n",
      "Request 51 took 133.74s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:04<00:00, 124.92s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 254/500 [2:06:25<2:04:07, 30.27s/it]\n",
      "Request 52 took 124.93s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:00<00:00, 120.64s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 259/500 [2:08:25<1:53:47, 28.33s/it]\n",
      "Request 53 took 120.64s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:53<00:00, 233.74s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 267/500 [2:12:19<2:12:16, 34.06s/it]\n",
      "Request 54 took 233.74s\n",
      "Generated 8 instructions, kept 8 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:07<00:00, 127.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 272/500 [2:14:26<1:40:43, 26.51s/it]\n",
      "Request 55 took 127.08s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:40<00:00, 100.84s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 277/500 [2:16:07<1:32:08, 24.79s/it]\n",
      "Request 56 took 100.84s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:03<00:00, 63.17s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 279/500 [2:17:10<1:18:50, 21.40s/it]\n",
      "Request 57 took 63.18s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:55<00:00, 115.24s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 282/500 [2:19:05<1:35:51, 26.38s/it]\n",
      "Request 58 took 115.24s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:30<00:00, 150.65s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 287/500 [2:21:36<1:52:54, 31.81s/it]\n",
      "Request 59 took 150.66s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:11<00:00, 71.47s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 290/500 [2:22:47<1:29:47, 25.65s/it]\n",
      "Request 60 took 71.47s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:34<00:00, 94.12s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 293/500 [2:24:22<1:33:04, 26.98s/it]\n",
      "Request 61 took 94.13s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [00:37<00:00, 37.80s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 295/500 [2:24:59<1:19:58, 23.41s/it]\n",
      "Request 62 took 37.80s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:16<00:00, 76.24s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 298/500 [2:26:16<1:28:17, 26.22s/it]\n",
      "Request 63 took 76.25s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:36<00:00, 96.91s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 302/500 [2:27:53<1:32:22, 27.99s/it]\n",
      "Request 64 took 96.92s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:12<00:00, 72.57s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 305/500 [2:29:05<1:19:34, 24.48s/it]\n",
      "Request 65 took 72.57s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:51<00:00, 111.71s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 310/500 [2:30:57<1:28:41, 28.01s/it]\n",
      "Request 66 took 111.72s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:06<00:00, 126.97s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 313/500 [2:33:04<1:24:03, 26.97s/it]\n",
      "Request 67 took 126.97s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:09<00:00, 129.24s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 318/500 [2:35:13<1:34:13, 31.06s/it]\n",
      "Request 68 took 129.24s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:42<00:00, 162.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 323/500 [2:37:55<1:33:08, 31.57s/it]\n",
      "Request 69 took 162.08s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:37<00:00, 97.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 325/500 [2:39:32<1:19:40, 27.32s/it]\n",
      "Request 70 took 97.07s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:27<00:00, 87.61s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 329/500 [2:41:00<1:25:41, 30.07s/it]\n",
      "Request 71 took 87.62s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [00:59<00:00, 59.46s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 332/500 [2:41:59<1:10:27, 25.17s/it]\n",
      "Request 72 took 59.46s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:45<00:00, 105.38s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 336/500 [2:43:45<1:15:47, 27.73s/it]\n",
      "Request 73 took 105.39s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:45<00:00, 105.82s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 340/500 [2:45:31<1:12:49, 27.31s/it]\n",
      "Request 74 took 105.82s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 25 Aug 2023 05:39:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7fc17587ce594d01-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [07:22<00:00, 442.79s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 343/500 [2:52:53<2:21:08, 53.94s/it]\n",
      "Request 75 took 442.79s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:23<00:00, 143.19s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 348/500 [2:55:17<2:12:38, 52.36s/it]\n",
      "Request 76 took 143.19s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:45<00:00, 165.73s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 353/500 [2:58:02<1:50:30, 45.10s/it]\n",
      "Request 77 took 165.74s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:08<00:00, 128.51s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 358/500 [3:00:11<1:30:39, 38.30s/it]\n",
      "Request 78 took 128.51s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 25 Aug 2023 05:54:12 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7fc18b0528564cd5-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [08:51<00:00, 531.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 365/500 [3:09:02<2:17:09, 60.96s/it]\n",
      "Request 79 took 531.07s\n",
      "Generated 7 instructions, kept 7 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:41<00:00, 101.31s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 368/500 [3:10:43<1:33:11, 42.36s/it]\n",
      "Request 80 took 101.31s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:52<00:00, 112.50s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 372/500 [3:12:36<1:28:19, 41.40s/it]\n",
      "Request 81 took 112.50s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:26<00:00, 86.89s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 375/500 [3:14:03<1:15:04, 36.04s/it]\n",
      "Request 82 took 86.89s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:27<00:00, 87.76s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 378/500 [3:15:30<1:10:09, 34.50s/it]\n",
      "Request 83 took 87.76s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:39<00:00, 99.78s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 383/500 [3:17:10<1:06:41, 34.20s/it]\n",
      "Request 84 took 99.78s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:45<00:00, 105.94s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 385/500 [3:18:56<56:23, 29.42s/it]\n",
      "Request 85 took 105.95s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:22<00:00, 82.57s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 388/500 [3:20:19<58:45, 31.48s/it]\n",
      "Request 86 took 82.57s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:34<00:00, 154.62s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 393/500 [3:22:53<1:05:50, 36.92s/it]\n",
      "Request 87 took 154.62s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:25<00:00, 85.85s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 396/500 [3:24:19<50:33, 29.17s/it]\n",
      "Request 88 took 85.86s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:20<00:00, 140.55s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [3:26:40<55:28, 33.62s/it]\n",
      "Request 89 took 140.55s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:17<00:00, 77.61s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 404/500 [3:27:58<42:56, 26.84s/it]\n",
      "Request 90 took 77.62s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 25 Aug 2023 06:21:24 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7fc1b3b58dbe4cc2-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [07:50<00:00, 470.14s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 409/500 [3:35:48<1:28:35, 58.41s/it]\n",
      "Request 91 took 470.15s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:07<00:00, 127.22s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 414/500 [3:37:55<1:06:24, 46.33s/it]\n",
      "Request 92 took 127.22s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:49<00:00, 109.46s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 419/500 [3:39:44<51:12, 37.93s/it]\n",
      "Request 93 took 109.47s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:21<00:00, 141.70s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 424/500 [3:42:06<44:02, 34.78s/it]\n",
      "Request 94 took 141.71s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:08<00:00, 128.52s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 429/500 [3:44:15<37:43, 31.87s/it]\n",
      "Request 95 took 128.52s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:30<00:00, 90.83s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 432/500 [3:45:46<31:15, 27.58s/it]\n",
      "Request 96 took 90.84s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:27<00:00, 87.93s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 435/500 [3:47:13<30:16, 27.94s/it]\n",
      "Request 97 took 87.93s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:42<00:00, 102.56s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 437/500 [3:48:56<30:51, 29.40s/it]\n",
      "Request 98 took 102.56s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:26<00:00, 86.43s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 440/500 [3:50:22<31:54, 31.90s/it]\n",
      "Request 99 took 86.43s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:03<00:00, 123.26s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 443/500 [3:52:26<32:44, 34.47s/it]\n",
      "Request 100 took 123.26s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:18<00:00, 198.85s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 450/500 [3:55:45<36:17, 43.56s/it]\n",
      "Request 101 took 198.86s\n",
      "Generated 7 instructions, kept 7 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:11<00:00, 71.51s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 453/500 [3:56:56<21:23, 27.30s/it]\n",
      "Request 102 took 71.51s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:13<00:00, 133.94s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 458/500 [3:59:10<21:54, 31.29s/it]\n",
      "Request 103 took 133.94s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:09<00:00, 129.14s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 463/500 [4:01:19<18:06, 29.36s/it]\n",
      "Request 104 took 129.14s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:25<00:00, 85.25s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 465/500 [4:02:45<14:42, 25.23s/it]\n",
      "Request 105 took 85.25s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:19<00:00, 139.12s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 470/500 [4:05:04<16:10, 32.36s/it]\n",
      "Request 106 took 139.12s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:35<00:00, 155.36s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 475/500 [4:07:39<13:17, 31.89s/it]\n",
      "Request 107 took 155.36s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:31<00:00, 91.29s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 478/500 [4:09:10<09:58, 27.22s/it]\n",
      "Request 108 took 91.29s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:16<00:00, 76.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 478/500 [4:10:27<09:58, 27.22s/it]\n",
      "Request 109 took 76.86s\n",
      "Generated 0 instructions, kept 0 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:31<00:00, 91.75s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 481/500 [4:11:59<10:42, 33.80s/it]\n",
      "Request 110 took 91.76s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:08<00:00, 128.68s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 485/500 [4:14:08<09:00, 36.03s/it]\n",
      "Request 111 took 128.68s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:02<00:00, 182.52s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 492/500 [4:17:10<05:12, 39.09s/it]\n",
      "Request 112 took 182.52s\n",
      "Generated 7 instructions, kept 7 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:52<00:00, 172.12s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 498/500 [4:20:02<01:05, 32.67s/it]\n",
      "Request 113 took 172.13s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:21<00:00, 81.11s/it]\n",
      "\n",
      "\n",
      "100%|██████████| 500/500 [4:21:23<00:00, 31.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [4:21:23<00:00, 25.93s/it]\n",
      "Request 114 took 81.11s\n",
      "Generated 2 instructions, kept 2 instructions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ret = generate_instruction_following_chat_data(output_dir=\"./gpt4_generation/cot_full_v4\",\n",
    "                                        instruction_prompt_file=\"./prompts_for_gpt/robot_cot_prompts_v4.txt\",\n",
    "                                        seed_example_path=\"./prompts_for_gpt/seeded_example_cot_v4.jsonl\",\n",
    "                                        seed_tasks_path=\"./gpt4_generation/task_generation_v2/split_1.jsonl\",\n",
    "                                        num_instructions_to_generate=500,\n",
    "                                        output_file=\"cot_instrut_regen_2.json\"\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "utils.full_inst_json_to_full_form_json('./gpt4_generation/cot_full_v4/cot_instrut_regen.json', \n",
    "                                       './gpt4_generation/cot_full_v4/cot_instrut_regen_formatted.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lists = list(open(\"./gpt4_generation_cot/cot_instrut_regen_gorilla.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_lists[0]\n",
    "data = json.loads(data)['code']\n",
    "if '###Instruction.' in data:\n",
    "    data = data.replace('###Instruction.', '###Instruction:')\n",
    "if 'Output:' in data:\n",
    "    a = {'instruction':data.split('Output:')[0].split('Instruction:')[1].split('###')[0],\n",
    "        'input': data.split('Output:')[0].split('Input:')[1].split('###')[0],\n",
    "        'output': data.split('Output:')[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" {'explanation': No. We don't know the weight of the blocks, need to infer weight first., 'code': <nooutput>.}\\n\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split('Output:')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "201e8860b8e6658cdfe301dc13e2a8b5ecdc17e6f5f25d00e326e3c8c2d13630"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
