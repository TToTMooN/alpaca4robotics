{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_robot_instruction import encode_task_generation_prompt, generate_task_data, encode_instruct_prompt, generate_instruction_following_chat_data, post_process_chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\nHere is the information about the environment. The environment is called {Two Block World}\\xa0\\nThere is a 7DOF Franka robot with a parallel gripper.\\xa0\\nThere are two blocks, {block A} and {block B}, with randomized sizes and density in the environment.\\nThe blocks are initialized at a random position on a table.\\nContents in the {} are the names of the objects in the environment.\\n\\nCome up with 10 different tasks for the robot to perform.\\n\\nGenerate the response following the template below:\\n### Task {i}: {task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\n\\nAn example task description is: {pick up the heavier block and place it on top of the lighter block}\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn't need to include all the objects in the environment.\\n3. You can assume the robot can do basic manipulation skills with a single parallel gripper.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height by stacking the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. The observation of the robot is the position and orientation of both blocks and the end effector of the robot, and the force sensor on the end effector. Try to devise tasks that are not trivial to solve with the initial observation. In other words, there are uncertainties in the task that requires the robot to explore the environment to solve the task. For tasks you think satisfy this requirement, please add a * at the end of the task description. For example, {pick up the heavier block and place it on top of the lighter block}*.\\n\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = encode_task_generation_prompt()\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=message,\n",
    "    temperature=1.0,\n",
    "    top_p=1,\n",
    "    max_tokens=512,)\n",
    "response = output['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<OpenAIObject at 0x7f8dd9558ef0> JSON: {\n",
       "   \"index\": 0,\n",
       "   \"message\": {\n",
       "     \"role\": \"assistant\",\n",
       "     \"content\": \"### Task 1: Pick up block B and place it directly next to block A without altering the initial orientation of block A*.\\n### Task 2: Manipulate block A and block B such that they are on the opposite sides of the table*.\\n### Task 3: Maximize the height by stacking the two blocks on top of each other*.\\n### Task 4: Pick up the lighter block and place it on the ground beneath the table without touching the heavier block.\\n### Task 5: Rotate block A 90 degrees without moving it from its initial position*.\\n### Task 6: Identify which block is denser, then lift that block and place it on top of the other block*.\\n### Task 7: Reorient blocks A and B such that they are at 180 degrees from each other with the heaviest block on the table and the lighter block on top of it*.\\n### Task 8: Move both block A and block B to the corners of the table.\\n### Task 9: Arrange blocks A and B side by side with a gap of at least 5cm between them*.\\n### Task 10: Determine which block is taller and place the shorter block on top of the taller block*.\"\n",
       "   },\n",
       "   \"finish_reason\": \"stop\"\n",
       " }]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_task_response(response):\n",
    "    if response is None:\n",
    "        return []\n",
    "    ### Parse the response into list of tasks ###\n",
    "    raw_tasks = re.split(\"###\", response)\n",
    "    print(raw_tasks)\n",
    "    tasks = []\n",
    "    for idx, task in enumerate(raw_tasks):\n",
    "        # # if the decoding stops due to length, the last example is likely truncated so we discard it\n",
    "        # if idx == len(raw_tasks) - 1 and response[\"finish_reason\"] == \"length\":\n",
    "        #     continue\n",
    "        ##### Parse the response into task #####\n",
    "        splitted_data = re.split(f\"{idx}:\\s+\", task)\n",
    "        if len(splitted_data) != 2:\n",
    "            continue\n",
    "        else:\n",
    "            task = splitted_data[1].strip()\n",
    "\n",
    "        ##### FILTER OUT Negative Examples #####\n",
    "        # filter out too short or too long tasks\n",
    "        if len(task.split()) <= 3 or len(task.split()) > 150:\n",
    "            continue\n",
    "        # filter based on keywords that are not suitable for language models.\n",
    "        # filter those starting with punctuation\n",
    "        if task[0] in string.punctuation:\n",
    "            continue\n",
    "        # filter those starting with non-english character\n",
    "        if not task[0].isascii():\n",
    "            continue\n",
    "        tasks.append(task)\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 machine-generated tasks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [[{'role': 'user', 'content': \"You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\nHere is the information about the environment. The environment is called {Two Block World}\\xa0\\nThere is a 7DOF Franka robot with a parallel gripper.\\xa0\\nThere are two blocks, {block A} and {block B}, with randomized sizes and density in the environment.\\nThe Franka robot has a force sensor on the end effector.\\nThe Franka robot is mounted on a table.\\nThe blocks are initialized at a random position on the table.\\nContents in the {} are the names of the objects in the environment.\\n\\nCome up with 10 different tasks for the robot to perform.\\n\\nGenerate the response following the template below:\\n###Task {i}: {task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\n\\nAn example task description is: {pick up the heavier block and place it on top of the lighter block}\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn't need to include all the objects in the environment.\\n3. You can assume the robot can do basic manipulation skills with a single parallel gripper.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height by stacking the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. The observation of the robot is the position and orientation of both blocks and the end effector of the robot, and the force sensor on the end effector. Try to devise tasks that are not trivial to solve with the initial observation. In other words, there are uncertainties in the task that requires the robot to explore the environment to solve the task. For tasks you think satisfy this requirement, please add a * at the end of the task description. For example, {pick up the heavier block and place it on top of the lighter block}*.\\n\"}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompts: 100%|██████████| 1/1 [00:14<00:00, 14.07s/it]\n",
      "  2%|▏         | 1/50 [00:14<11:29, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Task 1: Stack block A on top of block B without inducing a net force change exceeding 5N on the force sensor.*\\n', 'Task 2: Repeatedly hand over block A from the left gripper to the right gripper without dropping it.\\n', 'Task 3: Move block B to the edge of the table and bring it back to the center without tipping it over.*\\n', 'Task 4: Exchange the positions of the two blocks without touching the table. \\n', 'Task 5: Arrange block B in a position relative to block A, where both are balanced on opposing corners.*\\n', 'Task 6: Rotate block A 180 degrees around its center axis without changing its position on the table.*\\n', 'Task 7: Determine the heavier block by lifting each block by a certain height. Then place the lighter block on top of the heavier one*.\\n', 'Task 8: Test the robustness of the gripper by applying varying loadings using block A and recording the force on the force sensor.*\\n', 'Task 9: Position block B such that its center of mass is directly over the center of block A.*\\n', 'Task 10: Determine the most stable orientation for block A by placing it at different orientations and recording the force on the force sensor.*']\n",
      "Request 1 took 14.08s\n",
      "Generated 10 tasks, kept 10 instructions\n",
      "### [[{'role': 'user', 'content': \"You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\nHere is the information about the environment. The environment is called {Two Block World}\\xa0\\nThere is a 7DOF Franka robot with a parallel gripper.\\xa0\\nThere are two blocks, {block A} and {block B}, with randomized sizes and density in the environment.\\nThe Franka robot has a force sensor on the end effector.\\nThe Franka robot is mounted on a table.\\nThe blocks are initialized at a random position on the table.\\nContents in the {} are the names of the objects in the environment.\\n\\nCome up with 10 different tasks for the robot to perform.\\n\\nGenerate the response following the template below:\\n###Task {i}: {task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\n\\nAn example task description is: {pick up the heavier block and place it on top of the lighter block}\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn't need to include all the objects in the environment.\\n3. You can assume the robot can do basic manipulation skills with a single parallel gripper.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height by stacking the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. The observation of the robot is the position and orientation of both blocks and the end effector of the robot, and the force sensor on the end effector. Try to devise tasks that are not trivial to solve with the initial observation. In other words, there are uncertainties in the task that requires the robot to explore the environment to solve the task. For tasks you think satisfy this requirement, please add a * at the end of the task description. For example, {pick up the heavier block and place it on top of the lighter block}*.\\n\"}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompts: 100%|██████████| 1/1 [00:12<00:00, 12.86s/it]\n",
      " 22%|██▏       | 11/50 [00:26<01:22,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' Task 1: Stack block A on top of block B regardless of their weight.\\n', ' Task 2: Drop the heavier block on top of the lighter one such that the lighter block sustains minimum damage.*\\n', ' Task 3: Move block B to the edge of the table without letting it fall.*\\n', ' Task 4: Position the two blocks next to each other in such a way that they touch each other from the largest flat surfaces.*\\n', ' Task 5: Arrange the blocks in ascending order of their mass starting from the left side of the table.*\\n', ' Task 6: Flip block A upside down without touching block B.*\\n', ' Task 7: Stack block B over block A only if block B is lighter.*\\n', ' Task 8: Move block A to the right-most corner of the table.*\\n', \" Task 9: Align the two blocks by one of their sides making sure they don't overlap.*\\n\", ' Task 10: Maximize the distance between the two blocks on the table.*']\n",
      "Request 2 took 12.87s\n",
      "Generated 10 tasks, kept 10 instructions\n",
      "### [[{'role': 'user', 'content': \"You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\nHere is the information about the environment. The environment is called {Two Block World}\\xa0\\nThere is a 7DOF Franka robot with a parallel gripper.\\xa0\\nThere are two blocks, {block A} and {block B}, with randomized sizes and density in the environment.\\nThe Franka robot has a force sensor on the end effector.\\nThe Franka robot is mounted on a table.\\nThe blocks are initialized at a random position on the table.\\nContents in the {} are the names of the objects in the environment.\\n\\nCome up with 10 different tasks for the robot to perform.\\n\\nGenerate the response following the template below:\\n###Task {i}: {task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\n\\nAn example task description is: {pick up the heavier block and place it on top of the lighter block}\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn't need to include all the objects in the environment.\\n3. You can assume the robot can do basic manipulation skills with a single parallel gripper.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height by stacking the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. The observation of the robot is the position and orientation of both blocks and the end effector of the robot, and the force sensor on the end effector. Try to devise tasks that are not trivial to solve with the initial observation. In other words, there are uncertainties in the task that requires the robot to explore the environment to solve the task. For tasks you think satisfy this requirement, please add a * at the end of the task description. For example, {pick up the heavier block and place it on top of the lighter block}*.\\n\"}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompts: 100%|██████████| 1/1 [00:17<00:00, 17.06s/it]\n",
      " 60%|██████    | 30/50 [00:44<00:29,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Task 1: Pick up block A and place it on block B without tipping over block B*.\\n', 'Task 2: Arrange block A and block B side by side on the table with block A on the right and block B on the left*.\\n', 'Task 3: Determine which block is denser based by lifting each block and comparing the force sensor readings*.\\n', 'Task 4: Stack block A directly on top of block B without tilting either block*.\\n', 'Task 5: Reorder the blocks from left to right on the table based on their weight, with the heavier block on the left*.\\n', 'Task 6: Pick up and then release block B from a predefined height to simulate a drop test*.\\n', 'Task 7: Rotate block B 90 degrees clockwise while keeping it in its initial position*.\\n', 'Task 8: Move block A to the leftmost area of the table and block B to the rightmost area without changing their initial orientations*.\\n', 'Task 9: Balance block B on top of block A, without any part of block B hanging over the edge of block A*.\\n', \"Task 10: Move block A to the front right corner of the table and block B to the rear left corner, considering the skewed view from the Franka robot's placement*.\"]\n",
      "Request 3 took 17.07s\n",
      "Generated 10 tasks, kept 10 instructions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_task_data(num_tasks_to_generate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 60 machine-generated instructions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [[{'role': 'user', 'content': 'You are asked to come up with a set of 10 task instructions and corresponding responses. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model for completing the instructions.\\n\\nThe instruction and response pairs are happening between the robot and a chatbot guider in a robotic environment.\\n\\nHere is the information about the {environment}. \\n\\nThe environment is called \"Two Block World\" \\nThere is a 7DOF Franka robot with a parallel gripper.\\xa0\\nThere are two blocks, {block A} and {block B}, with randomized sizes and density in the environment.\\nThe Franka robot has a force sensor on the end effector.\\nThe Franka robot is mounted on a table.\\nThe blocks are initialized at a random position on the table.\\n\\nThe robot is given a long horizon task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}. \\n\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions, it will attach the previous step {instruction}, {input}, {output} at the begining of instruction if it\\'s not the first round of chat.\\n\\nThe {input} consists of the current observation of the robot. If it\\'s not provided, it will be <noinput>.\\n\\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part include an description of the reasoning process and the current planned action.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nBelow is the list of {FUNCTION}s provided in the robot skill library in this environment.\\n\\'\\'\\'\\ndef reach(position, orientation[optional])\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion(optional).\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped.\\n\\'\\'\\'\\ndef place(object_name, position, orientation[optional])\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion(optional).\\n\\'\\'\\'\\ndef move_to(position, orientation[optional])\\n\\'\\'\\'\\nThe skill of moving the end effector to a desired pose. position is a 3D vector and orientation is a quaternion(optional).\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n{TRAJECTORY_PLACEHOLDER}\\n\\nBelow is the list of {TASK}s used in the generated instructions can be chosen from a task list:\\n1. {\\'task\\': \\'Identify and pick up the lighter block and move it to the opposite end of the table*.\\'}\\n2. {\\'task\\': \\'Drop the heavier block on top of the lighter one such that the lighter block sustains minimum damage.*\\'}\\n3. {\\'task\\': \\'Move block B to the edge of the table without letting it fall.*\\'}\\n4. {\\'task\\': \\'Position the two blocks next to each other in such a way that they touch each other from the largest flat surfaces.*\\'}\\n5. {\\'task\\': \\'Arrange the blocks in ascending order of their mass starting from the left side of the table.*\\'}\\n6. {\\'task\\': \\'Flip block A upside down without touching block B.*\\'}\\n7. {\\'task\\': \\'Stack block B over block A only if block B is lighter.*\\'}\\n8. {\\'task\\': \\'Move block A to the right-most corner of the table.*\\'}\\n9. {\\'task\\': \"Align the two blocks by one of their sides making sure they don\\'t overlap.*\"}\\n10. {\\'task\\': \\'Maximize the distance between the two blocks on the table.*\\'}\\n11. {\\'task\\': \\'Pick up block A and place it on block B without tipping over block B*.\\'}\\n12. {\\'task\\': \\'Arrange block A and block B side by side on the table with block A on the right and block B on the left*.\\'}\\n13. {\\'task\\': \\'Determine which block is denser based by lifting each block and comparing the force sensor readings*.\\'}\\n14. {\\'task\\': \\'Stack block A directly on top of block B without tilting either block*.\\'}\\n15. {\\'task\\': \\'Reorder the blocks from left to right on the table based on their weight, with the heavier block on the left*.\\'}\\n16. {\\'task\\': \\'Pick up and then release block B from a predefined height to simulate a drop test*.\\'}\\n17. {\\'task\\': \\'Rotate block B 90 degrees clockwise while keeping it in its initial position*.\\'}\\n18. {\\'task\\': \\'Move block A to the leftmost area of the table and block B to the rightmost area without changing their initial orientations*.\\'}\\n19. {\\'task\\': \\'Balance block B on top of block A, without any part of block B hanging over the edge of block A*.\\'}\\n20. {\\'task\\': \"Move block A to the front right corner of the table and block B to the rear left corner, considering the skewed view from the Franka robot\\'s placement*.\"}\\n\\n\\nHere are some basic requirements for the generated instructions:\\n1. A GPT language model should be able to complete the instruction. For example, do not ask the assistant to create any visual or audio output. For another example, do not ask the assistant to wake you up at 5pm or set a reminder because it cannot perform any action.\\n2. The instructions should be in English.\\n3. The i-th response need to satisfy the following format: \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n\\n4. The format of {instruction} will be a question. Usually it will be a question about the next action the robot should take based on the task information and robot observation. It can also input the previous step {instruction}, {input}, {output} at the begining of instruction if it\\'s not the first round of chat. \\n5. The format of {input} will be a vector of robot observation. The input should involve all the states in the robot obvervation. There might be <placeholer> in the examples\\' input, but replace them with actual numbers in the generated instruction pairs.\\n6. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n7. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n8. You should generate exact 10 instruction pairs, and make sure they are distributed among different {TASK}s.\\n\\nExamples of instruction pairs are given below. Note that this could be instructions under different {TASK}s. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task>: stack block A on block B\\n <Instruction>: Based on the current observation, is it enough to plan and solve the task? If yes, what are the executed skills?\\n <Input>: [[0.20, 0.30, 1.025], [<placeholder>], [0.35, 0.5, 1.025], [<placeholder>], [0.0, 0.0, 1.50], [<placeholder>], [<placeholder>], [<placeholder>]]\\n <Output>:\\n[verbal] Yes, the current information is enough to plan and solve the task.\\n[action] [grasp(blockA), place(blockA, [0.75, 0.5, 1.15])].\\n###\\n <Task>: stack the heavier on the ligher block\\n <Instruction>: Based on the current observation, is it enough to plan and solve the task? If yes, what are the executed skills?\\n <Input>: [[0.20, 0.30, 1.025], [<placeholder>], [0.35, 0.5, 1.025], [<placeholder>], [0.0, 0.0, 1.50], [<placeholder>], [<placeholder>], [<placeholder>]]\\n <Output>:\\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action][grasp(blockA), grasp(blockB)].\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "generate_instruction_following_chat_data(num_instructions_to_generate=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_tasks_path=\"./prompts/seeded_tasks.jsonl\"\n",
    "seed_example_path=\"./prompts/seeded_example.jsonl\"\n",
    "function_file_path=\"./prompts/skill_functions.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "seed_tasks = [json.loads(l) for l in open(seed_tasks_path, \"r\")]\n",
    "seed_instructions = [json.loads(l) for l in open(seed_example_path, \"r\")]\n",
    "functions = [json.loads(l) for l in open(function_file_path, \"r\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input = []\n",
    "for _ in range(1):\n",
    "    # only sampling from the seed tasks\n",
    "    # prompt_instructions = random.sample(seed_instruction_data, num_prompt_instructions)\n",
    "    prompt = encode_instruct_prompt(\n",
    "        tasks=seed_tasks,\n",
    "        functions=functions,\n",
    "        examples=seed_instructions,\n",
    "    )\n",
    "    batch_input.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [[{'role': 'user', 'content': 'You are asked to come up with a set of 20 task instructions and corresponding responses. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model for completing the instructions.\\n\\nThe instruction and response pairs are happening between the robot and a chatbot guider in a robotic environment.\\n\\nHere is the information about the {environment}. \\n\\nThe environment is called \"Two Block World\" \\nThere is a 7DOF Franka robot with a parallel gripper. \\nThere are 2 blocks, {block A} and {block B} with randomized sizes and density in the environment.\\nThe blocks are initialized at a random position on a table.\\nContents in the {} are the names of the objects in the environment.\\n\\nThe robot is given a long horizon task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}. \\n\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions, it will attach the previous step {instruction}, {input}, {output} at the begining of instruction if it\\'s not the first round of chat.\\n\\nThe {input} consists of the current observation of the robot. If it\\'s not provided, it will be <noinput>.\\n\\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part include an description of the reasoning process and the current planned action.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nBelow is the list of {FUNCTION}s provided in the robot skill library in this environment.\\n\\'\\'\\'\\ndef reach(position, orientation[optional])\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion(optional).\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped.\\n\\'\\'\\'\\ndef place(object_name, position, orientation[optional])\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion(optional).\\n\\'\\'\\'\\ndef move_to(position, orientation[optional])\\n\\'\\'\\'\\nThe skill of moving the end effector to a desired pose. position is a 3D vector and orientation is a quaternion(optional).\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\nBelow is the list of {TASK}s used in the generated instructions can be chosen from a task list:\\n1. {\\'task\\': \\'Identify and pick up the lighter block and move it to the opposite end of the table*.\\'}\\n2. {\\'task\\': \\'Methodically stack block A on top of block B regardless of their weight, in an attempt to maximize their combined height.\\'}\\n3. {\\'task\\': \"Pick and hold block A and shake it gently without dropping it to understand the nature and density of the block\\'s material.*\"}\\n4. {\\'task\\': \\'Using the force sensor, apply a specific amount of force against block B, moving it a certain distance across the table.\\'}\\n\\n\\nHere are some basic requirements for the generated instructions:\\n1. A GPT language model should be able to complete the instruction. For example, do not ask the assistant to create any visual or audio output. For another example, do not ask the assistant to wake you up at 5pm or set a reminder because it cannot perform any action.\\n2. The instructions should be in English.\\n3. The i-th response need to satisfy the following format: \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {function output}\\n// end of instruction pair i, not including this line.\\n\\n4. The format of {instruction} will be a question. Usually it will be a question about the next action the robot should take based on the task information and robot observation.\\n5. The format of {input} will be a vector of robot observation. If there are <placeholer> in the input, it means the robot does not provide observation of this state at this step.\\n6. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n7. The format of {action output} will be {function name} {function parameter}. This should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n8. You should generate exact 20 instruction pairs, and make sure they are distributed among different {TASK}s.\\n\\nExamples of instruction pairs are given below. Note that this could be instructions under different {TASK}s. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n###\\n###\\n###\\n###\\n###\\n <Task>: stack block A on block B\\n <Instruction>: Based on the current observation, is it enough to plan and solve the task? If yes, what are the executed skills?\\n <Input>: [[0.20, 0.30, 1.025], [<placeholder>], [0.35, 0.5, 1.025], [<placeholder>], [0.0, 0.0, 1.50], [<placeholder>], [<placeholder>], [<placeholder>]]\\n <Output>:\\n<verbal output>Yes, the current information is enough to plan and solve the task.\\n<action output>[grasp(blockA), place(blockA, [0.75, 0.5, 1.15])].\\n###\\n <Task>: stack the heavier on the ligher block\\n <Instruction>: Based on the current observation, is it enough to plan and solve the task? If yes, what are the executed skills?\\n <Input>: [[0.20, 0.30, 1.025], [<placeholder>], [0.35, 0.5, 1.025], [<placeholder>], [0.0, 0.0, 1.50], [<placeholder>], [<placeholder>], [<placeholder>]]\\n <Output>:\\n<verbal output>No. We don\\'t know the weight of the blocks, need to infer weight first.\\n<action output>[grasp(blockA), grasp(blockB)].\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompts: 100%|██████████| 1/1 [02:14<00:00, 134.13s/it]\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "decoding_args = utils.OpenAIChatDecodingArguments(\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    max_tokens=2048,\n",
    "    stop=[\"\\n21\", \"21.\"],\n",
    ")\n",
    "chatcompletions = utils.openai_chatcompletion(\n",
    "    prompts=batch_input,\n",
    "    model_name=\"gpt-4\",\n",
    "    decoding_args=decoding_args,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = []\n",
    "for completion in chatcompletions:\n",
    "    new_instructions = post_process_chat_response(completion)\n",
    "    instructions += new_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "9\n",
      "['', '[verbal]', ' Based on the density, block A is lighter. The strategy will be to pick up block A and then place it at the position [1.75, 2.75, 0.75].\\n', '[action]', ' reach([1.12, 1.45, 0.75]), grasp(blockA), place(blockA, [1.75, 2.75, 0.75])']\n",
      "9\n",
      "['', '[verbal]', ' Yes, the robot should be able to reach block A.\\n', '[action]', ' reach([1.12, 1.45, 0.75])']\n",
      "9\n",
      "['', '[verbal]', ' The robot should reach towards block A, grasp it, bring it over block B, then place it on top.\\n', '[action]', ' reach([2, 4, 0.75]), grasp(blockA), place(blockA, [2.5, 3.75, 1.2])']\n",
      "9\n",
      "['', '[verbal]', ' The robot should reach towards block A, grasp it and then shake it. Shaking will be simulated by moving the grasped block back and forth.\\n', '[action]', ' reach([1.75, 2.5, 0.45]), grasp(blockA), move_to([1.75, 2.5, 0.65]), move_to([1.75, 2.5, 0.45])']\n",
      "9\n",
      "['', '[verbal]', ' The lighter block, which is Block A, should be placed at the position [1.75, 2.75, 0.75]. \\n', '[action]', ' place(blockA, [1.75, 2.75, 0.75])']\n",
      "9\n",
      "['', '[verbal]', ' No, in this case you should reach for block A first as we are stacking it on top of block B.\\n', '[action]', ' reach([2, 4, 0.75])']\n",
      "9\n",
      "['', '[verbal]', ' Block A should be placed at the position [2.5, 3.75, 1.2] to stack it on top of block B.\\n', '[action]', ' place(blockA, [2.5, 3.75, 1.2])']\n",
      "9\n",
      "['', '[verbal]', ' You can reach the block A from its current position which is [1.75, 2.5, 0.45].\\n', '[action]', ' reach([1.75, 2.5, 0.45])']\n",
      "9\n",
      "['', '[verbal]', ' To apply force to block B, robot should reach to it, grasp it, and move to the desired position.\\n', '[action]', ' reach([2.5, 3.75, 0.45]), grasp(blockB), move_to([3, 3.75, 0.45])']\n",
      "9\n",
      "['', '[verbal]', ' After applying force, block B can be moved to the position [3, 3.75, 0.45].\\n', '[action]', ' move_to([3, 3.75, 0.45])']\n",
      "9\n",
      "['', '[verbal]', ' With respect to the provided densities, block A seems to be lighter.\\n', '[action]', ' <noaction>']\n",
      "9\n",
      "['', '[verbal]', ' Yes, we can stack block A on block B without knowing their weights.\\n', '[action]', ' reach([2, 4, 0.75]), grasp(blockA), place(blockA, [2.5, 3.75, 1.2])']\n",
      "9\n",
      "['', '[verbal]', ' As there is no time parameter in the task, the decision will be arbitrary, for example, a two-step shake.\\n', '[action]', ' move_to([1.75, 2.5, 0.65]), move_to([1.75, 2.5, 0.45])']\n",
      "9\n",
      "['', '[verbal]', ' You can use your gripper to apply force and push block B across the table.\\n', '[action]', ' reach([2.5, 3.75, 0.45]), grasp(blockB), move_to([3, 3.75, 0.45])']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "response = completion\n",
    "raw_instructions = response[\"message\"][\"content\"]\n",
    "raw_instructions = re.split(\"###\", raw_instructions)\n",
    "\n",
    "for idx, inst in enumerate(raw_instructions):\n",
    "    # if the decoding stops due to length, the last example is likely truncated so we discard it\n",
    "    if idx == len(raw_instructions) - 1 and response[\"finish_reason\"] == \"length\":\n",
    "        continue\n",
    "    ##### Parse the response into instruction, input, output #####\n",
    "    idx += 1\n",
    "    splitted_data = re.split(f\"(<Task>|<Instruction>|<Input>|<Output>)\", inst)\n",
    "    print(len(splitted_data))\n",
    "    if len(splitted_data) != 9:\n",
    "        continue\n",
    "    else:\n",
    "        task = splitted_data[2].strip()\n",
    "        inst = splitted_data[4].strip()\n",
    "        input = splitted_data[6].strip()\n",
    "        input = \"\" if input.lower() == \"<noinput>\" else input\n",
    "        output = splitted_data[8].strip()\n",
    "        # parse output into <verbal output> and <action output>\n",
    "        output_splitted_data = re.split(\n",
    "            f\"(\\[verbal\\]|\\[action\\])\", output\n",
    "        )\n",
    "        print(output_splitted_data)\n",
    "        verbal_output = output_splitted_data[2].strip()\n",
    "        action_output = output_splitted_data[4].strip()\n",
    "        ##### FILTER OUT Negative Examples #####\n",
    "        # filter out too short or too long instructions\n",
    "        if len(inst.split()) <= 3 or len(inst.split()) > 150:\n",
    "            continue\n",
    "        # filter based on keywords that are not suitable for language models.\n",
    "        # filter those starting with punctuation\n",
    "        if inst[0] in string.punctuation:\n",
    "            continue\n",
    "        # filter those starting with non-english character\n",
    "        if not inst[0].isascii():\n",
    "            continue\n",
    "        instructions.append(\n",
    "            {\n",
    "                \"task\": task,\n",
    "                \"instruction\": inst,\n",
    "                \"input\": input,\n",
    "                \"verbal_output\": verbal_output,\n",
    "                \"action_output\": action_output,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "data = utils.jload(\"./subtask_data/grasp_A_example_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    d = d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "201e8860b8e6658cdfe301dc13e2a8b5ecdc17e6f5f25d00e326e3c8c2d13630"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
