{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_robot_instruction import encode_task_generation_prompt, generate_task_data, encode_instruct_prompt, generate_instruction_following_chat_data, post_process_chat_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [[{'role': 'user', 'content': 'You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. \\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assupmtion Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment.\\n<four> There are four blocks in the environment.\\n\\n[Your Task]\\nCome up with 50 different tasks for the robot to perform. Each designed under the assumption tags.\\n\\n[Output format]\\nThe response should follow the template below:\\n### Task {i}: {task tag}{task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn\\'t need to include all the objects in the environment.\\n3. The basic skills the robot can do is reach, grasp, and place. The task should not be out of its capability.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height of the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. You can include tasks with different levels of difficulties. Eazy tasks have short action sequences. Harder tasks have longer horizon which requires reasoning in planning.\\n8. Some tasks are not solvable with the initial observation. There are uncertainties in the task that requires the robot to explore the environment to gather information. For tasks you think satisfy this requirement, please add a * at the end of the task description.\\n9. At least 30% of the tasks should be non-solvable with the initial observation. \\n10. Tags can be combined together.\\n\\n[Example]\\nExamples of {task tag}{task description}: \\n<weight> pick up the heavier block and place it on top of the lighter block*\\n<move> find the movable block and place it on top of the other block.\\n<weight> move the heavier block to the corner of the table\\n<three><weight> sort all the blocks by their weight\\n<three> stack the three blocks\\n\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "prompts: 100%|██████████| 1/1 [02:57<00:00, 177.89s/it]\n",
      "  0%|          | 1/200 [02:57<9:50:01, 177.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' Task 1: <weight> Pick up the heavier block and place it on top of the lighter block*\\n', ' Task 2: <move> Find the movable block and place it on top of the other block*\\n', ' Task 3: <weight> Move the heavier block to the corner of the table*\\n', ' Task 4: <three><weight> Sort all the blocks by their weight*\\n', ' Task 5: <three> Stack the three blocks in a neat tower*\\n', ' Task 6: <four> Stack the blocks in a 2x2 square*\\n', ' Task 7: <weight> Swap the positions of the two blocks, placing the heavier block where the lighter block was*\\n', ' Task 8: <move> Stack both movable blocks on top of the immovable block*\\n', ' Task 9: <three> Create a pyramid with the three blocks*\\n', ' Task 10: <weight><three> Move the lightest block to the opposite side of the table*\\n', ' Task 11: <move><four> Find and stack the two movable blocks together*\\n', ' Task 12: <weight><four> Move the heaviest block to the center of the table*\\n', ' Task 13: <four> Create a staircase with the four blocks*\\n', ' Task 14: <move> Move the movable block to the edge of the table*\\n', ' Task 15: <three> Create a straight line with the three blocks along the edge of the table*\\n', ' Task 16: <weight> Balance the heavier block on top of the lighter block, creating a T shape*\\n', ' Task 17: <four> Arrange the blocks in a diamond shape on the table*\\n', \" Task 18: <weight> Gently pick up the lighter block without disturbing the heavier block's position*\\n\", ' Task 19: <move><three> Move one movable block onto the other movable block, creating a two-block tower*\\n', ' Task 20: <weight><three> Move the lightest block completely off the table*\\n', ' Task 21: <four> Stack the blocks in pairs of two*\\n', ' Task 22: <move> Move the movable block in a circular path around the immovable block*\\n', ' Task 23: <three> Create an L shape with the three blocks*\\n', ' Task 24: <three><weight> Create a triangle with the blocks, placing the heaviest one on top*\\n', ' Task 25: <move> Push the immovable block to the point farthest from the movable block*\\n', ' Task 26: <move><four> Stack one movable block on top of another and place both on the immovable block*\\n', ' Task 27: <move> Position the immovable block in between the fingers of the gripper*\\n', ' Task 28: <two><move> Slide the movable block under the immovable one*\\n', ' Task 29: <three><weight> Stack the three blocks in descending order based on their weight*\\n', ' Task 30: <four> Place one block on each corner of the table*\\n', ' Task 31: <weight><move> Lift the lighter, immovable block with one gripper finger while balancing the heavier, movable block on the other finger*\\n', ' Task 32: <three> Stack the three blocks in a Leaning Tower of Pisa formation*\\n', ' Task 33: <four><weight> Arrange the blocks in a square, placing the lighter ones diagonally across from each other*\\n', ' Task 34: <move> Push the movable block to a new position without disturbing the immovable block*\\n', ' Task 35: <three> Arrange the blocks in a growing-size order without any block touching each other*\\n', ' Task 36: <weight> Use the gripper to roll the lighter block to a new position on the table*\\n', ' Task 37: <move> Move the movable block so that it balances precariously on the edge of the table*\\n', ' Task 38: <four> Align two blocks in a straight line and stack the other two on top in a crisscross manner*\\n', ' Task 39: <three> Stack two blocks, then fit the third one snuggly into the gap between them, forming a triangle*\\n', ' Task 40: <four><weight> Arrange the four blocks in a rectangle shape based on their weight, with the heaviest two side by side and the lightest two side by side, on the opposite side of the rectangle*\\n', ' Task 41: <move><four> Remove the bottom block from a tower of four stacked blocks without collapsing the tower*\\n', ' Task 42: <weight> Use the gripper to hold the heavier block vertically by one end, then drop it to create a domino effect with the lighter block*\\n', ' Task 43: <three> Arrange the blocks in a reverse pyramid with the heaviest one at the top*\\n', ' Task 44: <move> Nudge the movable block against the immovable block to create a small gap between them*\\n', ' Task 45: <weight><three> Position the blocks equidistant from each other, with the heaviest block at the center*\\n', ' Task 46: <move><four> Divide the four blocks into two groups. Stack the movable blocks in one group and the immovable blocks in the other*\\n', ' Task 47: <weight><move> Use the force sensor to determine which block is heavier, then move and stack the lighter block on the heavier one*\\n', ' Task 48: <three> Arrange the blocks in a straight line order from front to back based on their size*\\n', ' Task 49: <weight><four> Only manipulate the two lighter blocks on the table and attempt to build a structure using those two blocks*\\n', ' Task 50: <move> Sweep the movable block across the table without losing contact with the gripper*']\n",
      "Request 1 took 177.90s\n",
      "Generated 50 tasks, kept 50 instructions\n",
      "### [[{'role': 'user', 'content': 'You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. \\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assupmtion Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment.\\n<four> There are four blocks in the environment.\\n\\n[Your Task]\\nCome up with 50 different tasks for the robot to perform. Each designed under the assumption tags.\\n\\n[Output format]\\nThe response should follow the template below:\\n### Task {i}: {task tag}{task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn\\'t need to include all the objects in the environment.\\n3. The basic skills the robot can do is reach, grasp, and place. The task should not be out of its capability.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height of the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. You can include tasks with different levels of difficulties. Eazy tasks have short action sequences. Harder tasks have longer horizon which requires reasoning in planning.\\n8. Some tasks are not solvable with the initial observation. There are uncertainties in the task that requires the robot to explore the environment to gather information. For tasks you think satisfy this requirement, please add a * at the end of the task description.\\n9. At least 30% of the tasks should be non-solvable with the initial observation. \\n10. Tags can be combined together.\\n\\n[Example]\\nExamples of {task tag}{task description}: \\n<weight> pick up the heavier block and place it on top of the lighter block*\\n<move> find the movable block and place it on top of the other block.\\n<weight> move the heavier block to the corner of the table\\n<three><weight> sort all the blocks by their weight\\n<three> stack the three blocks\\n\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "prompts: 100%|██████████| 1/1 [02:28<00:00, 148.11s/it]\n",
      " 26%|██▌       | 51/200 [05:26<13:21,  5.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' Task 1: <weight> Pick up the heavier block and place it on top of the lighter block*\\n', ' Task 2: <move> Find the movable block and place it on top of the other block*\\n', ' Task 3: <weight> Move the heavier block to the corner of the table*\\n', ' Task 4: <three><weight> Sort all the blocks by their weight*\\n', ' Task 5: <three> Stack the three blocks\\n', ' Task 6: <four> Create a 2x2 block square\\n', ' Task 7: <move><weight> Stack the movable blocks by weight*\\n', ' Task 8: <four><move> Create two stacks of two movable blocks each\\n', ' Task 9: <weight> Swap the positions of the blocks based on their weight*\\n', ' Task 10: <three> Create a pyramid with the three blocks\\n', ' Task 11: <three><move> Rearrange the movable blocks in a line*\\n', ' Task 12: <four><weight> Arrange the four blocks in ascending order of weight*\\n', ' Task 13: <move> Place the movable block on the edge of the table\\n', ' Task 14: <three><move> Move the movable block to the leftmost position*\\n', ' Task 15: <four> Create a tower with the four blocks\\n', ' Task 16: <weight><three> Move the lightest block to the edge of the table*\\n', ' Task 17: <move> Grasp and shake the movable block*\\n', ' Task 18: <four><move> Stack two movable blocks on one side of the table and the other two on the opposite side\\n', ' Task 19: <weight> Move the lighter block to a corner of the table and the heavier block to the opposite corner*\\n', ' Task 20: <four><weight> Create a weighted block pyramid with the heaviest block at the bottom and the lightest at the top*\\n', ' Task 21: <three> Place the blocks in a triangular formation\\n', ' Task 22: <four><move> Arrange the movable blocks in a square formation*\\n', ' Task 23: <weight> Move the lighter block under the heavier block, keeping them in their respective vertical positions*\\n', ' Task 24: <four> Place the blocks in each corner of the table\\n', ' Task 25: <three><move> Create a triangle using the movable blocks as vertices*\\n', ' Task 26: <four><weight> Arrange the blocks in a zigzag pattern based on their weight*\\n', ' Task 27: <three><move> Stack the movable blocks and place the unmovable block next to the stack\\n', ' Task 28: <four><move> Create an L-shape using the movable blocks\\n', ' Task 29: <weight> Attempt to lift the heavier block and place it down immediately after*\\n', ' Task 30: <three> Stack the three blocks diagonally on the table\\n', ' Task 31: <four><weight> Place the heaviest block on top of the lightest one in a cross pattern*\\n', ' Task 32: <move> Move the movable block to the center of the table\\n', ' Task 33: <three><move> Create a straight line using the movable blocks*\\n', ' Task 34: <four> Arrange the blocks to create a plus sign\\n', ' Task 35: <weight><three> Move the medium-weight block on top of the heaviest block*\\n', \" Task 36: <move> Attempt to push the movable block with the robot's end effector*\\n\", ' Task 37: <four><move> Create a diamond shape with the movable blocks\\n', ' Task 38: <weight> Stack the lighter block on top of the heavier block in a diagonal pattern*\\n', ' Task 39: <three> Arrange the three blocks in a horizontal line\\n', ' Task 40: <four><weight> Create two towers of two blocks each with the heaviest blocks at the bottoms*\\n', ' Task 41: <three><weight> Move the lightest block away from the heaviest block\\n', ' Task 42: <move> Move the movable block under the unmovable block*\\n', ' Task 43: <four> Create an S-shape with the four blocks\\n', ' Task 44: <weight> Move the heavier block to the center of the table and stack the lighter block on top\\n', ' Task 45: <four><move> Stack a movable block on top of the unmovable block*\\n', ' Task 46: <three> Arrange the blocks in a vertical row\\n', \" Task 47: <move> Slide the movable block towards the robot's base*\\n\", ' Task 48: <weight> Attempt to lift the lighter block as quickly as possible and place it back down*\\n', ' Task 49: <four><weight> Stack the blocks in pairs according to their weights*\\n', ' Task 50: <move> Move the movable block back and forth between two points on the table*']\n",
      "Request 2 took 148.12s\n",
      "Generated 50 tasks, kept 50 instructions\n",
      "### [[{'role': 'user', 'content': 'You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. \\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assupmtion Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment.\\n<four> There are four blocks in the environment.\\n\\n[Your Task]\\nCome up with 50 different tasks for the robot to perform. Each designed under the assumption tags.\\n\\n[Output format]\\nThe response should follow the template below:\\n### Task {i}: {task tag}{task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn\\'t need to include all the objects in the environment.\\n3. The basic skills the robot can do is reach, grasp, and place. The task should not be out of its capability.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height of the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. You can include tasks with different levels of difficulties. Eazy tasks have short action sequences. Harder tasks have longer horizon which requires reasoning in planning.\\n8. Some tasks are not solvable with the initial observation. There are uncertainties in the task that requires the robot to explore the environment to gather information. For tasks you think satisfy this requirement, please add a * at the end of the task description.\\n9. At least 30% of the tasks should be non-solvable with the initial observation. \\n10. Tags can be combined together.\\n\\n[Example]\\nExamples of {task tag}{task description}: \\n<weight> pick up the heavier block and place it on top of the lighter block*\\n<move> find the movable block and place it on top of the other block.\\n<weight> move the heavier block to the corner of the table\\n<three><weight> sort all the blocks by their weight\\n<three> stack the three blocks\\n\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "prompts: 100%|██████████| 1/1 [02:47<00:00, 167.02s/it]\n",
      " 50%|█████     | 101/200 [08:13<06:54,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' Task 1: <weight> Pick up the heavier block and place it on top of the lighter block*\\n', ' Task 2: <move> Find the movable block and place it on top of the other block*\\n', ' Task 3: <weight> Move the heavier block to the corner of the table*\\n', ' Task 4: <three><weight> Sort all the blocks by their weight*\\n', ' Task 5: <three> Stack the three blocks*\\n', ' Task 6: <weight><move> Move both the movable and the heavier block to the opposite ends of the table*\\n', ' Task 7: <four> Arrange the four blocks in a square formation*\\n', ' Task 8: <three> Form a pyramid with the three blocks*\\n', ' Task 9: <four> Stack the four blocks in a balanced column*\\n', \" Task 10: <weight> Balance the heavier block on top of the lighter block's edge*\\n\", ' Task 11: <move> Stack the movable blocks on one side of the table and the non-movable blocks on the other side*\\n', ' Task 12: <four> Arrange the blocks in a line from the heaviest to lightest*\\n', ' Task 13: <four> Move the largest block to the center of the table and the other blocks around it, forming a triangle*\\n', ' Task 14: <three><weight> Place the heaviest block on top of the two lighter blocks, forming a bridge*\\n', ' Task 15: <weight> Swap the positions of the heavier block and the lighter block without moving any other block*\\n', ' Task 16: <three><move> Stack the blocks on top of each other such that only one is touching the table*\\n', ' Task 17: <weight><move> Push the non-movable blocks to the opposite end of the table without lifting them*\\n', ' Task 18: <four> Form a rectangular wall with the four blocks*\\n', ' Task 19: <weight> Pick up and shake the heavier block after finding it*\\n', ' Task 20: <three> Stack the blocks such that no two edges are aligned*\\n', ' Task 21: <weight><move> Swap the positions of the movable block with the heavier block*\\n', ' Task 22: <three> Stack the blocks in a zigzag pattern*\\n', ' Task 23: <move> Stand the movable block on one of its corners*\\n', ' Task 24: <four> Create a staircase with alternating movable and non-movable blocks*\\n', ' Task 25: <weight> Use the gripper and force sensor to sense the block weights without fully picking them up*\\n', ' Task 26: <four> Create a hollow square with the four blocks as corners*\\n', ' Task 27: <three><move> Place the movable block between the other two blocks*\\n', ' Task 28: <three><weight> Stack the lightest block on top of the middle-weight block, and then stack the heaviest block on top*\\n', ' Task 29: <four> Stack the blocks in a spiral pattern*\\n', ' Task 30: <weight> Move the heaviest block to the opposite corner of the table*\\n', ' Task 31: <four> Create a 2x2 square with the blocks*\\n', ' Task 32: <move> Stack the movable blocks on one side of the table and push the non-movable blocks to the other side*\\n', ' Task 33: <three> Stack the blocks vertically in a straight line*\\n', ' Task 34: <four> Arrange the blocks in a diamond shape on the table*\\n', ' Task 35: <weight> Propel the lighter block on its edge by pushing it*\\n', ' Task 36: <three><move> Stack the blocks such that the set of them resembles a pendulum*\\n', ' Task 37: <four> Create a cube configuration by connecting the blocks with their opposite corners touching*\\n', ' Task 38: <weight> Use the force sensor to push the lighter block across the table without lifting it*\\n', ' Task 39: <three> Stack the blocks as high as possible*\\n', ' Task 40: <move> Restack the blocks such that the previously blocked bottom block is the top block*\\n', ' Task 41: <four> Create a cross formation with the four blocks*\\n', ' Task 42: <three><weight> Place the lightest block on the heaviest block, and the medium-weight block on top of the lightest block*\\n', ' Task 43: <three> Form a V-shape with the blocks*\\n', ' Task 44: <weight> Lift the heaviest block with the minimum force possible*\\n', ' Task 45: <four> Stack the movable blocks and non-movable blocks in alternating layers*\\n', ' Task 46: <weight> Test the weight of both blocks and if both are equal, stack them*\\n', ' Task 47: <move> Stack the movable and non-movable blocks on top of each other, making sure each block is stacked on a different block type*\\n', ' Task 48: <four> Arrange the blocks in a triangle shape with one block in the center*\\n', ' Task 49: <three><weight> Place the heaviest block underneath the lighter blocks, supporting them*\\n', ' Task 50: <four> Create a symmetrical square with the blocks by arranging them diagonally*']\n",
      "Request 3 took 167.02s\n",
      "Generated 50 tasks, kept 50 instructions\n",
      "### [[{'role': 'user', 'content': 'You are serving as a task-generation helper for a given robot environment.\\xa0\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. \\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assupmtion Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment.\\n<four> There are four blocks in the environment.\\n\\n[Your Task]\\nCome up with 50 different tasks for the robot to perform. Each designed under the assumption tags.\\n\\n[Output format]\\nThe response should follow the template below:\\n### Task {i}: {task tag}{task description}\\nwhere {i} is the task number and {task description} is the task description.\\n\\nThe rules for task description:\\n1. Only include the objects in the environment in the task description.\\n2. The task description doesn\\'t need to include all the objects in the environment.\\n3. The basic skills the robot can do is reach, grasp, and place. The task should not be out of its capability.\\n4. The task description can be implicit in the objects. For example, {Pick up the heavier block} is a valid task description.\\n5. The task description can be implicit in the goal. For example, {Maximize the height of the two blocks} is a valid task description.\\n6. Use your imagination to come up with different tasks. The tasks should be diverse and not too similar to each other.\\n7. You can include tasks with different levels of difficulties. Eazy tasks have short action sequences. Harder tasks have longer horizon which requires reasoning in planning.\\n8. Some tasks are not solvable with the initial observation. There are uncertainties in the task that requires the robot to explore the environment to gather information. For tasks you think satisfy this requirement, please add a * at the end of the task description.\\n9. At least 30% of the tasks should be non-solvable with the initial observation. \\n10. Tags can be combined together.\\n\\n[Example]\\nExamples of {task tag}{task description}: \\n<weight> pick up the heavier block and place it on top of the lighter block*\\n<move> find the movable block and place it on top of the other block.\\n<weight> move the heavier block to the corner of the table\\n<three><weight> sort all the blocks by their weight\\n<three> stack the three blocks\\n\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "prompts: 100%|██████████| 1/1 [02:26<00:00, 146.71s/it]\n",
      "100%|██████████| 200/200 [10:39<00:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' Task 1: <weight> Pick up the heavier block*\\n', ' Task 2: <move> Find the movable block and place it on top of the immovable block*\\n', ' Task 3: <weight><move> Swap the positions of the movable block and the heavier block\\n', ' Task 4: <three> Stack the three blocks in any order\\n', ' Task 5: <four> Create a row with the four blocks\\n', ' Task 6: <weight> Move the lighter block to the edge of the table\\n', ' Task 7: <weight><three> Sort the three blocks by their weight\\n', ' Task 8: <three><move> Move the immovable block by pushing it with the movable block*\\n', ' Task 9: <four> Pick up two blocks and stack them one on top of the other\\n', ' Task 10: <weight> Move the lighter block on top of the heavier block*\\n', ' Task 11: <move> Push the immovable block to the corner of the table*\\n', ' Task 12: <weight> Place the heavier block in between the end effector and the lighter block\\n', ' Task 13: <three> Create an increasing height order of the three blocks\\n', ' Task 14: <weight><three> Move the lighter block between the other two blocks\\n', ' Task 15: <four> Create a square formation with the four blocks\\n', ' Task 16: <three> Move the leftmost block to the rightmost position\\n', ' Task 17: <weight><move> Move the immovable block by using the heavier block*\\n', ' Task 18: <weight><four> Stack the two lighter blocks on top of each other*\\n', ' Task 19: <weight><four><move> Sort the movable blocks by their weight\\n', ' Task 20: <three><move> Rotate the movable block to a specific orientation\\n', ' Task 21: <move> Move the movable block to the edge of the table\\n', ' Task 22: <four> Create a two by two formation with the blocks\\n', ' Task 23: <three> Stack the blocks in decreasing height order\\n', ' Task 24: <weight> Maximize the height of the two blocks*\\n', ' Task 25: <weight><three> Place the heaviest block under the other two blocks\\n', ' Task 26: <four><move> Place the movable blocks on top of each other\\n', ' Task 27: <weight><three> Stack the heaviest block in the middle of the other two blocks\\n', ' Task 28: <move> Move the movable block from the highest position to the lowest position\\n', ' Task 29: <four> Stack the blocks in the following order: A, B, C, D\\n', ' Task 30: <weight><move> Touch the lighter block without changing its position\\n', ' Task 31: <three> Create a bridge formation with the three blocks\\n', ' Task 32: <weight><four> Move the heaviest block to the edge of the table\\n', ' Task 33: <four> Arrange the blocks in a diagonal line\\n', ' Task 34: <weight><move> Bring the movable block closer to the heavier block\\n', ' Task 35: <three> Stack the blocks such that the middle block is on the bottom\\n', ' Task 36: <move> Place the movable block vertically\\n', ' Task 37: <four> Arrange the blocks in an X formation\\n', ' Task 38: <weight><four> Bring the lighter block closer to the heaviest block\\n', ' Task 39: <three> Align the three blocks along the edge of the table\\n', ' Task 40: <weight><move> Stack the movable block on top of the heavier block\\n', ' Task 41: <four> Place the blocks in alternating height order\\n', ' Task 42: <weight><four> Sort all four blocks by their weight\\n', ' Task 43: <three> Move the middle block to the left of the leftmost block\\n', ' Task 44: <weight> Move both blocks to opposite corners of the table\\n', ' Task 45: <four><move> Move the movable blocks diagonally from each other\\n', ' Task 46: <three> Rotate all three blocks to have the same orientation\\n', ' Task 47: <move> Flip the movable block 180 degrees\\n', ' Task 48: <four> Form a pyramid structure with the four blocks\\n', ' Task 49: <weight> Move the heavier block to be parallel to the lighter block\\n', ' Task 50: <three><move> Place the movable block in between the other two blocks, forming a line']\n",
      "Request 4 took 146.71s\n",
      "Generated 50 tasks, kept 50 instructions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_task_data(\n",
    "    output_dir=\"./gpt4_generation/task_generation_v2/\",\n",
    "    num_tasks_to_generate=200,\n",
    "    prompt_file_name=\"./prompts_for_gpt/robot_task_prompt_v2.txt\",\n",
    "    model_name=\"gpt-4-0314\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split task data\n",
    "Split it into tasks used by instruction generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import string\n",
    "import json\n",
    "def split_json_file(json_file, \n",
    "                    output_path, n=2):\n",
    "  \"\"\"Splits a JSON file into N JSONL files, where each file contains n elements.\n",
    "\n",
    "  Args:\n",
    "    json_file: The path to the JSON file to split.\n",
    "    n: The number of JSONL files to create.\n",
    "\n",
    "  Returns:\n",
    "    The list of paths to the created JSONL files.\n",
    "  \"\"\"\n",
    "\n",
    "  with open(json_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "  os.makedirs(output_path, exist_ok=True)\n",
    "  jsonl_files = []\n",
    "  for i in range(0, len(data), n):\n",
    "    jsonl_file = f\"{output_path}split_{i // n}.jsonl\"\n",
    "    with open(jsonl_file, \"w\") as outfile:\n",
    "      for record in data[i : i + n]:\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "    jsonl_files.append(jsonl_file)\n",
    "  return jsonl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_files = split_json_file(json_file=\"./gpt4_generation/task_generation_v2/task_regen.json\",\n",
    "                              output_path=\"./gpt4_generation/task_generation_v2/\",\n",
    "                              n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate COT instruct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [[{'role': 'system', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 12+7*n dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions starts from 1. Index for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. \\n\\n'}, {'role': 'user', 'content': \"\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {'task': '<weight> Pick up the heavier block and place it on top of the lighter block*'}\\n2. {'task': '<move> Find the movable block and place it on top of the other block*'}\\n3. {'task': '<weight> Move the heavier block to the corner of the table*'}\\n4. {'task': '<three><weight> Sort all the blocks by their weight*'}\\n\\n\\n[Function Lists in skill library]\\n'''\\ndef reach(position, orientation)\\n'''\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n'''\\ndef grasp(object_name)\\n'''\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n'''\\ndef place(object_name, position, orientation)\\n'''\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n'''\\ndef reset()\\n'''\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example observations]\\nBelow is some example observations when executing some skills. Use them as reference for observations when generating instructions.\\nEnding observation of the robot finishing the provided skills:\\n'''\\nSkill name: grasp\\nParameters: blockA\\nFinal Obs: [-0.09, 0.25, 1.2, -0.02, 0.02, -0.14, 0.99, 0.06, -0.24, 1.06, -0.0, 0.0, 0.37, 0.93, -0.09, 0.25, 1.2, 0.8, 0.6, -0.0, -0.0, 0.96, -0.18, -1.8, 0.02, 0.02]\\n'''\\n'''\\nSkill name: place\\nParameters: [[0.06, -0.24, 1.14], [0.76, 0.65, 0.0, 0.0]]\\nFinal Obs: [0.05, -0.25, 1.12, -0.0, -0.0, -0.02, 1.0, 0.06, -0.24, 1.06, -0.0, -0.0, 0.37, 0.93, 0.06, -0.24, 1.3, 0.76, 0.65, 0.0, 0.0, -0.01, -0.0, 0.0, 0.04, 0.04]\\n'''\\n\\n\\n[Example instruction pairs]\\nBelow is some example instruction pairs. Use them as reference when generating instructions.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don't know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don't know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n\\nIgnore the index in the example and start from 1. for the tasks in TASK list. Do not stop generating until all the tasks are covered.\\n\\n\"}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:08<00:00, 128.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [02:08<12:49, 128.30s/it]\n",
      "Request 1 took 128.30s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'system', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 12+7*n dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions starts from 1. Index for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. \\n\\n'}, {'role': 'user', 'content': \"\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {'task': '<three> Stack the three blocks in a neat tower*'}\\n2. {'task': '<four> Stack the blocks in a 2x2 square*'}\\n3. {'task': '<weight> Swap the positions of the two blocks, placing the heavier block where the lighter block was*'}\\n4. {'task': '<move> Stack both movable blocks on top of the immovable block*'}\\n\\n\\n[Function Lists in skill library]\\n'''\\ndef reach(position, orientation)\\n'''\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n'''\\ndef grasp(object_name)\\n'''\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n'''\\ndef place(object_name, position, orientation)\\n'''\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n'''\\ndef reset()\\n'''\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example observations]\\nBelow is some example observations when executing some skills. Use them as reference for observations when generating instructions.\\nEnding observation of the robot finishing the provided skills:\\n'''\\nSkill name: grasp\\nParameters: blockA\\nFinal Obs: [-0.09, 0.25, 1.2, -0.02, 0.02, -0.14, 0.99, 0.06, -0.24, 1.06, -0.0, 0.0, 0.37, 0.93, -0.09, 0.25, 1.2, 0.8, 0.6, -0.0, -0.0, 0.96, -0.18, -1.8, 0.02, 0.02]\\n'''\\n'''\\nSkill name: place\\nParameters: [[0.06, -0.24, 1.14], [0.76, 0.65, 0.0, 0.0]]\\nFinal Obs: [0.05, -0.25, 1.12, -0.0, -0.0, -0.02, 1.0, 0.06, -0.24, 1.06, -0.0, -0.0, 0.37, 0.93, 0.06, -0.24, 1.3, 0.76, 0.65, 0.0, 0.0, -0.01, -0.0, 0.0, 0.04, 0.04]\\n'''\\n\\n\\n[Example instruction pairs]\\nBelow is some example instruction pairs. Use them as reference when generating instructions.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don't know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don't know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n\\nIgnore the index in the example and start from 1. for the tasks in TASK list. Do not stop generating until all the tasks are covered.\\n\\n\"}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:52<00:00, 172.40s/it]\n",
      "12it [05:00, 25.06s/it]                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12it [05:00, 55.79s/it]\n",
      "Request 2 took 172.40s\n",
      "Generated 8 instructions, kept 8 instructions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from generate_robot_instruction import generate_instruction_following_chat_data\n",
    "\n",
    "\n",
    "ret = generate_instruction_following_chat_data(output_dir=\"./gpt4_generation/cot_full_v5\",\n",
    "                                        instruction_prompt_file=\"./prompts_for_gpt/robot_cot_prompts_v5.txt\",\n",
    "                                        seed_example_path=\"./prompts_for_gpt/seeded_example_cot_v4.jsonl\",\n",
    "                                        seed_tasks_path=\"./gpt4_generation/task_generation_v2/split_0.jsonl\",\n",
    "                                        num_instructions_to_generate=10,\n",
    "                                        num_of_tasks_each_request=3,\n",
    "                                        use_sub_skill_data=True,\n",
    "                                        output_file=\"cot_instrut_regen.json\"\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Pick up the heavier block and place it on top of the lighter block*\\'}\\n2. {\\'task\\': \\'<move> Find the movable block and place it on top of the other block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:32<00:00, 152.83s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/500 [02:32<21:00:49, 152.83s/it]\n",
      "Request 1 took 152.83s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Move the heavier block to the corner of the table*\\'}\\n2. {\\'task\\': \\'<three><weight> Sort all the blocks by their weight*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:36<00:00, 96.17s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/500 [04:08<4:51:39, 35.64s/it]\n",
      "Request 2 took 96.17s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Stack the three blocks*\\'}\\n2. {\\'task\\': \\'<weight><move> Move both the movable and the heavier block to the opposite ends of the table*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:34<00:00, 154.79s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/500 [06:43<5:00:27, 37.17s/it]\n",
      "Request 3 took 154.79s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Arrange the four blocks in a square formation*\\'}\\n2. {\\'task\\': \\'<three> Form a pyramid with the three blocks*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:26<00:00, 146.14s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 21/500 [09:09<4:03:48, 30.54s/it]\n",
      "Request 4 took 146.14s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Stack the four blocks in a balanced column*\\'}\\n2. {\\'task\\': \"<weight> Balance the heavier block on top of the lighter block\\'s edge*\"}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:44<00:00, 104.25s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 25/500 [10:54<3:17:28, 24.94s/it]\n",
      "Request 5 took 104.25s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Stack the movable blocks on one side of the table and the non-movable blocks on the other side*\\'}\\n2. {\\'task\\': \\'<four> Arrange the blocks in a line from the heaviest to lightest*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:30<00:00, 90.01s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 29/500 [12:24<3:10:17, 24.24s/it]\n",
      "Request 6 took 90.02s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Move the largest block to the center of the table and the other blocks around it, forming a triangle*\\'}\\n2. {\\'task\\': \\'<three><weight> Place the heaviest block on top of the two lighter blocks, forming a bridge*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:48<00:00, 168.64s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 35/500 [15:12<3:48:22, 29.47s/it]\n",
      "Request 7 took 168.65s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Swap the positions of the heavier block and the lighter block without moving any other block*\\'}\\n2. {\\'task\\': \\'<three><move> Stack the blocks on top of each other such that only one is touching the table*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:19<00:00, 139.01s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 41/500 [17:31<3:26:53, 27.05s/it]\n",
      "Request 8 took 139.01s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><move> Push the non-movable blocks to the opposite end of the table without lifting them*\\'}\\n2. {\\'task\\': \\'<four> Form a rectangular wall with the four blocks*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:30<00:00, 150.65s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 47/500 [20:02<3:19:00, 26.36s/it]\n",
      "Request 9 took 150.66s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Pick up and shake the heavier block after finding it*\\'}\\n2. {\\'task\\': \\'<three> Stack the blocks such that no two edges are aligned*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:56<00:00, 116.28s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|█         | 53/500 [21:58<2:58:53, 24.01s/it]\n",
      "Request 10 took 116.29s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><move> Swap the positions of the movable block with the heavier block*\\'}\\n2. {\\'task\\': \\'<three> Stack the blocks in a zigzag pattern*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:04<00:00, 124.61s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 57/500 [24:03<2:49:31, 22.96s/it]\n",
      "Request 11 took 124.61s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Stand the movable block on one of its corners*\\'}\\n2. {\\'task\\': \\'<four> Create a staircase with alternating movable and non-movable blocks*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:36<00:00, 96.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 61/500 [25:39<2:49:49, 23.21s/it]\n",
      "Request 12 took 96.08s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Use the gripper and force sensor to sense the block weights without fully picking them up*\\'}\\n2. {\\'task\\': \\'<four> Create a hollow square with the four blocks as corners*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:05<00:00, 125.77s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 66/500 [27:45<3:02:55, 25.29s/it]\n",
      "Request 13 took 125.78s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three><move> Place the movable block between the other two blocks*\\'}\\n2. {\\'task\\': \\'<three><weight> Stack the lightest block on top of the middle-weight block, and then stack the heaviest block on top*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:14<00:00, 134.86s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 70/500 [30:00<3:04:59, 25.81s/it]\n",
      "Request 14 took 134.87s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Stack the blocks in a spiral pattern*\\'}\\n2. {\\'task\\': \\'<weight> Move the heaviest block to the opposite corner of the table*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:19<00:00, 79.90s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 74/500 [31:20<2:52:24, 24.28s/it]\n",
      "Request 15 took 79.90s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Create a 2x2 square with the blocks*\\'}\\n2. {\\'task\\': \\'<move> Stack the movable blocks on one side of the table and push the non-movable blocks to the other side*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:32<00:00, 92.44s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 78/500 [32:52<2:48:33, 23.97s/it]\n",
      "Request 16 took 92.45s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Stack the blocks vertically in a straight line*\\'}\\n2. {\\'task\\': \\'<four> Arrange the blocks in a diamond shape on the table*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:08<00:00, 128.16s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 82/500 [35:00<3:02:43, 26.23s/it]\n",
      "Request 17 took 128.17s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Propel the lighter block on its edge by pushing it*\\'}\\n2. {\\'task\\': \\'<three><move> Stack the blocks such that the set of them resembles a pendulum*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:23<00:00, 143.58s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 88/500 [37:24<3:19:04, 28.99s/it]\n",
      "Request 18 took 143.59s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Create a cube configuration by connecting the blocks with their opposite corners touching*\\'}\\n2. {\\'task\\': \\'<weight> Use the force sensor to push the lighter block across the table without lifting it*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:06<00:00, 126.24s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 91/500 [39:30<2:57:02, 25.97s/it]\n",
      "Request 19 took 126.24s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Stack the blocks as high as possible*\\'}\\n2. {\\'task\\': \\'<move> Restack the blocks such that the previously blocked bottom block is the top block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:55<00:00, 115.56s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 95/500 [41:26<3:13:22, 28.65s/it]\n",
      "Request 20 took 115.56s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Create a cross formation with the four blocks*\\'}\\n2. {\\'task\\': \\'<three><weight> Place the lightest block on the heaviest block, and the medium-weight block on top of the lightest block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:28<00:00, 88.92s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 99/500 [42:55<2:59:04, 26.79s/it]\n",
      "Request 21 took 88.92s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Form a V-shape with the blocks*\\'}\\n2. {\\'task\\': \\'<weight> Lift the heaviest block with the minimum force possible*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 25 Aug 2023 03:36:00 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7fc0c1f05e843b69-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [07:31<00:00, 451.47s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21%|██        | 105/500 [50:26<5:41:58, 51.95s/it]\n",
      "Request 22 took 451.47s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Stack the movable blocks and non-movable blocks in alternating layers*\\'}\\n2. {\\'task\\': \\'<weight> Test the weight of both blocks and if both are equal, stack them*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:41<00:00, 221.90s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 109/500 [54:08<5:00:58, 46.18s/it]\n",
      "Request 23 took 221.90s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Stack the movable and non-movable blocks on top of each other, making sure each block is stacked on a different block type*\\'}\\n2. {\\'task\\': \\'<four> Arrange the blocks in a triangle shape with one block in the center*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:39<00:00, 159.88s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 115/500 [56:48<4:45:39, 44.52s/it]\n",
      "Request 24 took 159.88s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three><weight> Place the heaviest block underneath the lighter blocks, supporting them*\\'}\\n2. {\\'task\\': \\'<four> Create a symmetrical square with the blocks by arranging them diagonally*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:16<00:00, 196.38s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 121/500 [1:00:04<4:14:01, 40.22s/it]\n",
      "Request 25 took 196.39s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Pick up the heavier block*\\'}\\n2. {\\'task\\': \\'<move> Find the movable block and place it on top of the immovable block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:31<00:00, 151.64s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 129/500 [1:02:36<3:37:00, 35.10s/it]\n",
      "Request 26 took 151.65s\n",
      "Generated 8 instructions, kept 8 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><move> Swap the positions of the movable block and the heavier block\\'}\\n2. {\\'task\\': \\'<three> Stack the three blocks in any order\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:15<00:00, 135.76s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 135/500 [1:04:52<2:49:56, 27.94s/it]\n",
      "Request 27 took 135.76s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Create a row with the four blocks\\'}\\n2. {\\'task\\': \\'<weight> Move the lighter block to the edge of the table\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:00<00:00, 180.52s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 142/500 [1:07:52<2:50:30, 28.58s/it]\n",
      "Request 28 took 180.52s\n",
      "Generated 7 instructions, kept 7 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><three> Sort the three blocks by their weight\\'}\\n2. {\\'task\\': \\'<three><move> Move the immovable block by pushing it with the movable block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [04:57<00:00, 297.66s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 150/500 [1:12:50<3:13:39, 33.20s/it]\n",
      "Request 29 took 297.66s\n",
      "Generated 8 instructions, kept 8 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Pick up two blocks and stack them one on top of the other\\'}\\n2. {\\'task\\': \\'<weight> Move the lighter block on top of the heavier block*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:10<00:00, 130.23s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|███       | 156/500 [1:15:00<2:36:16, 27.26s/it]\n",
      "Request 30 took 130.23s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Push the immovable block to the corner of the table*\\'}\\n2. {\\'task\\': \\'<weight> Place the heavier block in between the end effector and the lighter block\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:25<00:00, 145.35s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 161/500 [1:17:25<2:29:19, 26.43s/it]\n",
      "Request 31 took 145.36s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Create an increasing height order of the three blocks\\'}\\n2. {\\'task\\': \\'<weight><three> Move the lighter block between the other two blocks\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:04<00:00, 124.73s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 166/500 [1:19:30<2:25:06, 26.07s/it]\n",
      "Request 32 took 124.73s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Create a square formation with the four blocks\\'}\\n2. {\\'task\\': \\'<three> Move the leftmost block to the rightmost position\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:28<00:00, 88.31s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 170/500 [1:20:59<2:11:21, 23.88s/it]\n",
      "Request 33 took 88.32s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><move> Move the immovable block by using the heavier block*\\'}\\n2. {\\'task\\': \\'<weight><four> Stack the two lighter blocks on top of each other*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:31<00:00, 151.68s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 174/500 [1:23:30<2:27:13, 27.10s/it]\n",
      "Request 34 took 151.68s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><four><move> Sort the movable blocks by their weight\\'}\\n2. {\\'task\\': \\'<three><move> Rotate the movable block to a specific orientation\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 25 Aug 2023 04:16:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7fc0fd6688854cf3-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [07:31<00:00, 451.50s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 177/500 [1:31:02<4:19:38, 48.23s/it]\n",
      "Request 35 took 451.51s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Move the movable block to the edge of the table\\'}\\n2. {\\'task\\': \\'<four> Create a two by two formation with the blocks\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:20<00:00, 140.10s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 183/500 [1:33:22<4:13:08, 47.91s/it]\n",
      "Request 36 took 140.10s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Stack the blocks in decreasing height order\\'}\\n2. {\\'task\\': \\'<weight> Maximize the height of the two blocks*\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:30<00:00, 150.19s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 187/500 [1:35:52<3:25:20, 39.36s/it]\n",
      "Request 37 took 150.19s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><three> Place the heaviest block under the other two blocks\\'}\\n2. {\\'task\\': \\'<four><move> Place the movable blocks on top of each other\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:11<00:00, 71.68s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 191/500 [1:37:04<2:53:44, 33.73s/it]\n",
      "Request 38 took 71.68s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight><three> Stack the heaviest block in the middle of the other two blocks\\'}\\n2. {\\'task\\': \\'<move> Move the movable block from the highest position to the lowest position\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:17<00:00, 137.43s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 195/500 [1:39:21<2:52:21, 33.91s/it]\n",
      "Request 39 took 137.43s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Stack the blocks in the following order: A, B, C, D\\'}\\n2. {\\'task\\': \\'<weight><move> Touch the lighter block without changing its position\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:28<00:00, 148.96s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [1:41:50<2:53:37, 34.84s/it]\n",
      "Request 40 took 148.97s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Create a bridge formation with the three blocks\\'}\\n2. {\\'task\\': \\'<weight><four> Move the heaviest block to the edge of the table\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:44<00:00, 104.79s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41%|████      | 206/500 [1:43:35<2:18:46, 28.32s/it]\n",
      "Request 41 took 104.80s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Arrange the blocks in a diagonal line\\'}\\n2. {\\'task\\': \\'<weight><move> Bring the movable block closer to the heavier block\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:15<00:00, 135.87s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 212/500 [1:45:51<2:14:14, 27.97s/it]\n",
      "Request 42 took 135.87s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Stack the blocks such that the middle block is on the bottom\\'}\\n2. {\\'task\\': \\'<move> Place the movable block vertically\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:36<00:00, 96.49s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 217/500 [1:47:27<1:52:30, 23.85s/it]\n",
      "Request 43 took 96.49s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Arrange the blocks in an X formation\\'}\\n2. {\\'task\\': \\'<weight><four> Bring the lighter block closer to the heaviest block\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ").\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [04:20<00:00, 260.50s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 223/500 [1:51:48<2:28:11, 32.10s/it]\n",
      "Request 44 took 260.51s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Align the three blocks along the edge of the table\\'}\\n2. {\\'task\\': \\'<weight><move> Stack the movable block on top of the heavier block\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:10<00:00, 70.31s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 227/500 [1:52:58<1:55:07, 25.30s/it]\n",
      "Request 45 took 70.31s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four> Place the blocks in alternating height order\\'}\\n2. {\\'task\\': \\'<weight><four> Sort all four blocks by their weight\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:31<00:00, 91.02s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 230/500 [1:54:29<1:51:06, 24.69s/it]\n",
      "Request 46 took 91.02s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<three> Move the middle block to the left of the leftmost block\\'}\\n2. {\\'task\\': \\'<weight> Move both blocks to opposite corners of the table\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:51<00:00, 111.37s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 234/500 [1:56:21<2:00:46, 27.24s/it]\n",
      "Request 47 took 111.37s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<four><move> Move the movable blocks diagonally from each other\\'}\\n2. {\\'task\\': \\'<three> Rotate all three blocks to have the same orientation\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 234/500 [1:56:23<2:00:46, 27.24s/it]\n",
      "Request 48 took 2.27s\n",
      "Generated 0 instructions, kept 0 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<move> Flip the movable block 180 degrees\\'}\\n2. {\\'task\\': \\'<four> Form a pyramid structure with the four blocks\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:45<00:00, 105.69s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 238/500 [1:58:09<1:58:39, 27.17s/it]\n",
      "Request 49 took 105.69s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n1. {\\'task\\': \\'<weight> Move the heavier block to be parallel to the lighter block\\'}\\n2. {\\'task\\': \\'<three><move> Place the movable block in between the other two blocks, forming a line\\'}\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:57<00:00, 237.22s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 246/500 [2:02:06<2:34:00, 36.38s/it]\n",
      "Request 50 took 237.22s\n",
      "Generated 8 instructions, kept 8 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:13<00:00, 133.74s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 249/500 [2:04:20<1:55:09, 27.53s/it]\n",
      "Request 51 took 133.74s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:04<00:00, 124.92s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 254/500 [2:06:25<2:04:07, 30.27s/it]\n",
      "Request 52 took 124.93s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:00<00:00, 120.64s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 259/500 [2:08:25<1:53:47, 28.33s/it]\n",
      "Request 53 took 120.64s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:53<00:00, 233.74s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 267/500 [2:12:19<2:12:16, 34.06s/it]\n",
      "Request 54 took 233.74s\n",
      "Generated 8 instructions, kept 8 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:07<00:00, 127.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 272/500 [2:14:26<1:40:43, 26.51s/it]\n",
      "Request 55 took 127.08s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:40<00:00, 100.84s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 277/500 [2:16:07<1:32:08, 24.79s/it]\n",
      "Request 56 took 100.84s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:03<00:00, 63.17s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 279/500 [2:17:10<1:18:50, 21.40s/it]\n",
      "Request 57 took 63.18s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:55<00:00, 115.24s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 282/500 [2:19:05<1:35:51, 26.38s/it]\n",
      "Request 58 took 115.24s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:30<00:00, 150.65s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 287/500 [2:21:36<1:52:54, 31.81s/it]\n",
      "Request 59 took 150.66s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:11<00:00, 71.47s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 290/500 [2:22:47<1:29:47, 25.65s/it]\n",
      "Request 60 took 71.47s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:34<00:00, 94.12s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 293/500 [2:24:22<1:33:04, 26.98s/it]\n",
      "Request 61 took 94.13s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [00:37<00:00, 37.80s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 295/500 [2:24:59<1:19:58, 23.41s/it]\n",
      "Request 62 took 37.80s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:16<00:00, 76.24s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 298/500 [2:26:16<1:28:17, 26.22s/it]\n",
      "Request 63 took 76.25s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:36<00:00, 96.91s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 302/500 [2:27:53<1:32:22, 27.99s/it]\n",
      "Request 64 took 96.92s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:12<00:00, 72.57s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 305/500 [2:29:05<1:19:34, 24.48s/it]\n",
      "Request 65 took 72.57s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:51<00:00, 111.71s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 310/500 [2:30:57<1:28:41, 28.01s/it]\n",
      "Request 66 took 111.72s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:06<00:00, 126.97s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 313/500 [2:33:04<1:24:03, 26.97s/it]\n",
      "Request 67 took 126.97s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:09<00:00, 129.24s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 318/500 [2:35:13<1:34:13, 31.06s/it]\n",
      "Request 68 took 129.24s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:42<00:00, 162.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 323/500 [2:37:55<1:33:08, 31.57s/it]\n",
      "Request 69 took 162.08s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:37<00:00, 97.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 325/500 [2:39:32<1:19:40, 27.32s/it]\n",
      "Request 70 took 97.07s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:27<00:00, 87.61s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 329/500 [2:41:00<1:25:41, 30.07s/it]\n",
      "Request 71 took 87.62s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [00:59<00:00, 59.46s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 332/500 [2:41:59<1:10:27, 25.17s/it]\n",
      "Request 72 took 59.46s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:45<00:00, 105.38s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 336/500 [2:43:45<1:15:47, 27.73s/it]\n",
      "Request 73 took 105.39s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:45<00:00, 105.82s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 340/500 [2:45:31<1:12:49, 27.31s/it]\n",
      "Request 74 took 105.82s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 25 Aug 2023 05:39:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7fc17587ce594d01-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [07:22<00:00, 442.79s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 343/500 [2:52:53<2:21:08, 53.94s/it]\n",
      "Request 75 took 442.79s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:23<00:00, 143.19s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 348/500 [2:55:17<2:12:38, 52.36s/it]\n",
      "Request 76 took 143.19s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:45<00:00, 165.73s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 353/500 [2:58:02<1:50:30, 45.10s/it]\n",
      "Request 77 took 165.74s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:08<00:00, 128.51s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 358/500 [3:00:11<1:30:39, 38.30s/it]\n",
      "Request 78 took 128.51s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 25 Aug 2023 05:54:12 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7fc18b0528564cd5-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [08:51<00:00, 531.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 365/500 [3:09:02<2:17:09, 60.96s/it]\n",
      "Request 79 took 531.07s\n",
      "Generated 7 instructions, kept 7 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:41<00:00, 101.31s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 368/500 [3:10:43<1:33:11, 42.36s/it]\n",
      "Request 80 took 101.31s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:52<00:00, 112.50s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 372/500 [3:12:36<1:28:19, 41.40s/it]\n",
      "Request 81 took 112.50s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:26<00:00, 86.89s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 375/500 [3:14:03<1:15:04, 36.04s/it]\n",
      "Request 82 took 86.89s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:27<00:00, 87.76s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 378/500 [3:15:30<1:10:09, 34.50s/it]\n",
      "Request 83 took 87.76s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:39<00:00, 99.78s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 383/500 [3:17:10<1:06:41, 34.20s/it]\n",
      "Request 84 took 99.78s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:45<00:00, 105.94s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 385/500 [3:18:56<56:23, 29.42s/it]\n",
      "Request 85 took 105.95s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:22<00:00, 82.57s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 388/500 [3:20:19<58:45, 31.48s/it]\n",
      "Request 86 took 82.57s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:34<00:00, 154.62s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 393/500 [3:22:53<1:05:50, 36.92s/it]\n",
      "Request 87 took 154.62s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:25<00:00, 85.85s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 396/500 [3:24:19<50:33, 29.17s/it]\n",
      "Request 88 took 85.86s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:20<00:00, 140.55s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [3:26:40<55:28, 33.62s/it]\n",
      "Request 89 took 140.55s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:17<00:00, 77.61s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 404/500 [3:27:58<42:56, 26.84s/it]\n",
      "Request 90 took 77.62s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[AWARNING:root:OpenAIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 25 Aug 2023 06:21:24 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7fc1b3b58dbe4cc2-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [07:50<00:00, 470.14s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 409/500 [3:35:48<1:28:35, 58.41s/it]\n",
      "Request 91 took 470.15s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:07<00:00, 127.22s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 414/500 [3:37:55<1:06:24, 46.33s/it]\n",
      "Request 92 took 127.22s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:49<00:00, 109.46s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 419/500 [3:39:44<51:12, 37.93s/it]\n",
      "Request 93 took 109.47s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:21<00:00, 141.70s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 424/500 [3:42:06<44:02, 34.78s/it]\n",
      "Request 94 took 141.71s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:08<00:00, 128.52s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 429/500 [3:44:15<37:43, 31.87s/it]\n",
      "Request 95 took 128.52s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:30<00:00, 90.83s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 432/500 [3:45:46<31:15, 27.58s/it]\n",
      "Request 96 took 90.84s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:27<00:00, 87.93s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 435/500 [3:47:13<30:16, 27.94s/it]\n",
      "Request 97 took 87.93s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:42<00:00, 102.56s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 437/500 [3:48:56<30:51, 29.40s/it]\n",
      "Request 98 took 102.56s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:26<00:00, 86.43s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 440/500 [3:50:22<31:54, 31.90s/it]\n",
      "Request 99 took 86.43s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:03<00:00, 123.26s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 443/500 [3:52:26<32:44, 34.47s/it]\n",
      "Request 100 took 123.26s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:18<00:00, 198.85s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 450/500 [3:55:45<36:17, 43.56s/it]\n",
      "Request 101 took 198.86s\n",
      "Generated 7 instructions, kept 7 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:11<00:00, 71.51s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 453/500 [3:56:56<21:23, 27.30s/it]\n",
      "Request 102 took 71.51s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:13<00:00, 133.94s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 458/500 [3:59:10<21:54, 31.29s/it]\n",
      "Request 103 took 133.94s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:09<00:00, 129.14s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 463/500 [4:01:19<18:06, 29.36s/it]\n",
      "Request 104 took 129.14s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:25<00:00, 85.25s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 465/500 [4:02:45<14:42, 25.23s/it]\n",
      "Request 105 took 85.25s\n",
      "Generated 2 instructions, kept 2 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:19<00:00, 139.12s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 470/500 [4:05:04<16:10, 32.36s/it]\n",
      "Request 106 took 139.12s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:35<00:00, 155.36s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 475/500 [4:07:39<13:17, 31.89s/it]\n",
      "Request 107 took 155.36s\n",
      "Generated 5 instructions, kept 5 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:31<00:00, 91.29s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 478/500 [4:09:10<09:58, 27.22s/it]\n",
      "Request 108 took 91.29s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:16<00:00, 76.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 478/500 [4:10:27<09:58, 27.22s/it]\n",
      "Request 109 took 76.86s\n",
      "Generated 0 instructions, kept 0 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:31<00:00, 91.75s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 481/500 [4:11:59<10:42, 33.80s/it]\n",
      "Request 110 took 91.76s\n",
      "Generated 3 instructions, kept 3 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:08<00:00, 128.68s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 485/500 [4:14:08<09:00, 36.03s/it]\n",
      "Request 111 took 128.68s\n",
      "Generated 4 instructions, kept 4 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [03:02<00:00, 182.52s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 492/500 [4:17:10<05:12, 39.09s/it]\n",
      "Request 112 took 182.52s\n",
      "Generated 7 instructions, kept 7 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [02:52<00:00, 172.12s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 498/500 [4:20:02<01:05, 32.67s/it]\n",
      "Request 113 took 172.13s\n",
      "Generated 6 instructions, kept 6 instructions\n",
      "### [[{'role': 'user', 'content': 'You will be given a set of tasks in a robotic environment.\\nYou are asked to simulate the task instructions and corresponding responses happening during task solving.\\nSome of them are long-horizon tasks request multiple reasoning steps, so we are generating multi-turn instructions in a chain of thought way. \\nThese task instructions will be given to a GPT model and we will evaluate the GPT model performance on the generated responses.\\n\\n[General Environment Description] \\nThe environment is called \"Block World\". \\nThere is a 7DOF Franka Panda robot with a parallel gripper, it has a force sensor on the end effector. The robot is mounted on a table.\\nThere are multiple blocks on tha table, here we use 2 blocks as example. The blocks are called {block A} and {block B}. If there are more than two blocks, they are called {block C}, {block D}, etc.\\nThe blocks are initialized at a random position on the table.\\nThe observation space (when there are two blocks) is a 26 dimension vector, consisting of:\\nblock A position(3), block A orientation(4), block B position(3), block B orientation(4), end effector position(3), end effector orientation(4), end effector force(3), left finger position(1), right finger position(1) \\nIf there are more than two blocks, the observation space is a 26+7*(n-2) dimension vector, where n is the number of blocks.\\n\\n[Extra Environment Assumption Tags]\\n<weight> The blocks have randomized weight.\\n<move> The blocks are randomly determined to be movable or not, at least one block is movable.\\n<three> There are three blocks in the environment. They are identical and movable if there is no <weight> or <move> tag.\\n<four> There are four blocks in the environment. \\nTags at the beginning of {TASK} represent the environment assumptions for the task.\\n\\n[Instruction data Format]\\nThe robot will be given a task: {TASK}. \\nThe instructions and responses happen when the robot is trying to solve this specific {TASK}, and ask a chatbot guider.\\nEach instruction data pair consists of three parts: {instruction}, {input}, {output}\\nThe {instruction} consists of the question asked by the robot to help make decisions.\\nThe {input} consists of the current observation and historical info. \\nThe {output} consists of two parts <verbal> and <action>.\\n    - The <verbal> part describe the reasoning process and explanation for the current planned action if there is any.\\n    - The <action> part include a downstream action provided in the function lists executable by the robot. \\n\\nThe {instruction} of each task consists of the following standard questions in order to provide chain of thought instructions pairs.\\n1. Is the current information enough to solve the task? If not, what information is missing?\\n2. What are the actions the robot should take to gather information?\\n3. What are the actions the robot should take to solve the task?\\nFor the 1st question, the <action> output part should be <nooutput>, only <verbal> output is important. The robot should ask this every time it collects new information. \\nFor the other questions, both <verbal> and <action> output parts are important. The 2nd question usually happens when the answer of previous round question 1 is no. The 3rd question usually happens when the answer of previous round question 1 is yes.\\nWhen generating instruction data, please imagine the observation and previous collected information for the robot, and generate the corresponding {input} and {output}.\\nThere can be different responses to the same question depending on different {input}, imagine different scenarios and generate different responses. \\n\\n[Tasks to solve]\\nBelow is the list of {TASK}s used in the generated instructions:\\n\\n\\n[Function Lists in skill library]\\n\\'\\'\\'\\ndef reach(position, orientation)\\n\\'\\'\\'\\nThe skill of end effector reaching to a desired pose. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef grasp(object_name)\\n\\'\\'\\'\\nThe skill of grasping an object. object_name is the name of the object to be grasped. The skill will reach and grasp the object, no need to reach before grasp.\\n\\'\\'\\'\\ndef place(object_name, position, orientation)\\n\\'\\'\\'\\nThe skill of placing an object. object_name is the name of the object to be placed. position is a 3D vector and orientation is a quaternion.\\n\\'\\'\\'\\ndef reset()\\n\\'\\'\\'\\nThe skill of resetting the robot to its initial state.\\n\\n\\n[Example trajectories]\\nBelow is some example trajectories(sequence of obs) when executing some skills. Use them as reference for observations when generating instructions. If no example trajectory is provided, use your own imagination.\\n{TRAJECTORY_PLACEHOLDER}\\n\\n[Format of generated instructions]\\n1. The i-th response need to satisfy the following format, i starts from 1. \\n// start of instruction pair i, not including this line.\\n###\\ni.\\n<Task> {task}\\n<Instruction> {instruction}\\n<Input> {input}\\n<Output>\\n[verbal] {verbal output}\\n[action] {list of function output}\\n// end of instruction pair i, not including this line.\\n2. The index of instructions for different tasks are continous. For example, if the last instruction for task 1 is 5, the first instruction data for task 2 should be 6.\\n3. The format of {instruction}: It\\'s usually one of the questions listed above.\\n4. The format of {input} will be a vector of robot observation, followed by a list of historical information. Use actual numbers in the vectors. The format is: \\nCurrent:\\\\n[observation]\\\\nPast:\\\\n[hist text 1] [hist action list 1] [hist obs list 1]\\\\n[hist text 2] [hist action list 2] [hist obs list 2]\\\\n ...\\n[hist text] [hist action list] are the previous rounds explanation and action sequence, [hist obs list] is the observation after the action executions in previous rounds. The number of hist obs should correspond to the number of actions in hist action list. \\n5. The format of {verbal output} will be a sentence explain the current reasoning process and the current planned action. It is used for in-context learning for multi-turn instructions.\\n6. The format of {action output} will be list of {function name} {function parameter} wrapped by []. Each element should be in a python executable form, don\\'t use placeholders as parameters, output the numbers if the parameters are vectors.\\n7. Each instruction pair should be separated by a line of \"###\" at the beginning.\\n8. For each task in the task list, generate the multiple rounds of instructions from initial until the task is solved. At some steps, if there are multiple possible feecback observations, generate multiple data pairs with corresponding observations.\\nGenerate instructions for task 1 first, then task 2, ..., task N. \\nEach task should have at most 10 instruction pairs. Don\\'t stop generating instructions until all the tasks listed are covered.\\n\\nExamples of instruction pairs for a single turn are given below. Note that this could be instructions under different {TASK}s in different rounds. You need to modify the instruction pairs according to the {TASK}.\\n\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0.0, 0.0]\\nPast: [] [] []\\n <Output> \\n[verbal] No. We don\\'t know the weight of the blocks, need to infer weight first.\\n[action] <nooutput>.\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> What are the actions the robot should take to gather information?\\n <Input> [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.0, 0.0]\\nPast: [No. We don\\'t know the weight of the blocks, need to infer weight first.] [] []\\n <Output> \\n[verbal] We will grasp block A and B to infer their weight.\\n[action] [grasp(blockA), grasp(blockB)].\\n###\\n <Task> <weight> stack the heavier on the ligher block\\n <Instruction> Is the current information enough to solve the task? If not, what information is missing?\\n <Input> Current: [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\nPast: [We will grasp block A and B to infer their weight.] [grasp(blockA), grasp(blockB)] [[0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -1, 0.2, 0.2], [0.20, 0.30, 1.025, 0, 0, 0, 1, 0.35, 0.5, 1.025, 0, 0, 0, 1, 0.0, 0.0, 1.50, 0, 0, 0, 1, 0, 0, -2, 0.2, 0.2]]\\n <Output> \\n[verbal] Yes. Block B is heavier based on past observations\\n[action] <nooutput>.\\n'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "prompts: 100%|██████████| 1/1 [01:21<00:00, 81.11s/it]\n",
      "\n",
      "\n",
      "100%|██████████| 500/500 [4:21:23<00:00, 31.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [4:21:23<00:00, 25.93s/it]\n",
      "Request 114 took 81.11s\n",
      "Generated 2 instructions, kept 2 instructions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ret = generate_instruction_following_chat_data(output_dir=\"./gpt4_generation/cot_full_v4\",\n",
    "                                        instruction_prompt_file=\"./prompts_for_gpt/robot_cot_prompts_v4.txt\",\n",
    "                                        seed_example_path=\"./prompts_for_gpt/seeded_example_cot_v4.jsonl\",\n",
    "                                        seed_tasks_path=\"./gpt4_generation/task_generation_v2/split_1.jsonl\",\n",
    "                                        num_instructions_to_generate=500,\n",
    "                                        output_file=\"cot_instrut_regen_2.json\"\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "utils.full_inst_json_to_full_form_json('./gpt4_generation/cot_full_v4/cot_instrut_regen.json', \n",
    "                                       './gpt4_generation/cot_full_v4/cot_instrut_regen_formatted.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lists = list(open(\"./gpt4_generation_cot/cot_instrut_regen_gorilla.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_lists[0]\n",
    "data = json.loads(data)['code']\n",
    "if '###Instruction.' in data:\n",
    "    data = data.replace('###Instruction.', '###Instruction:')\n",
    "if 'Output:' in data:\n",
    "    a = {'instruction':data.split('Output:')[0].split('Instruction:')[1].split('###')[0],\n",
    "        'input': data.split('Output:')[0].split('Input:')[1].split('###')[0],\n",
    "        'output': data.split('Output:')[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" {'explanation': No. We don't know the weight of the blocks, need to infer weight first., 'code': <nooutput>.}\\n\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split('Output:')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "201e8860b8e6658cdfe301dc13e2a8b5ecdc17e6f5f25d00e326e3c8c2d13630"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
